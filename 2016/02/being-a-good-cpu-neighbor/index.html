<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>Being a good CPU neighbor</title><meta name="description" content="Making long-running CPU intensive processes not to suck every bit of CPU time from other processes in Linux."/><link rel="stylesheet" href="/css/main.css"/><link rel="canonical" href="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/"/><link rel="alternate" type="application/rss+xml" title="Jussi Judin's weblog" href="https://feeds.feedburner.com/jussijudin"/><link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon-180x180.png"/><link rel="icon" type="image/png" href="/icons/favicon-32x32.png" sizes="32x32"/><link rel="icon" type="image/png" href="/icons/android-chrome-192x192.png" sizes="192x192"/><link rel="icon" type="image/png" href="/icons/favicon-96x96.png" sizes="96x96"/><link rel="icon" type="image/png" href="/icons/favicon-16x16.png" sizes="16x16"/><link rel="manifest" href="/icons/manifest.json"/><link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#00a300"/><meta name="msapplication-TileImage" content="/icons/mstile-144x144.png"/><meta name="theme-color" content="#ffffff"/><meta content="928229747232422" property="fb:app_id"/><meta content="Jussi Judin's weblog" property="og:site_name"/><meta content="Being a good CPU neighbor" property="og:title"/><meta content="article" property="og:type"/><meta content="Making long-running CPU intensive processes not to suck every bit of CPU time from other processes in Linux." property="og:description"/><meta content="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/" property="og:url"/><meta content="2016-02-28T18:00:05+02:00" property="article:published_time"/><meta content="https://barro.github.io/author/" property="article:author"/><meta property="og:image" content="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/id-cropped-800x400.png"/><meta content="cpu-priority" property="article:tag"/><meta content="nice" property="article:tag"/><meta content="chrt" property="article:tag"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="@b4rr0"/><meta name="twitter:creator" content="@b4rr0"/><meta name="twitter:title" content="Being a good CPU neighbor"/><meta name="twitter:url" content="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/"/><meta name="twitter:description" content="Making long-running CPU intensive processes not to suck every bit of CPU time from other processes in Linux."/><meta name="twitter:image:src" content="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/id-square-400x400.png"/></head><body><header class="site-header"><div class="wrapper"><a class="site-title" href="/">Jussi Judin's weblog</a><nav class="site-nav"> <a href="#" class="menu-icon"> <svg viewBox="0 0 18 15"> <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/> <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/> <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/> </svg> </a><div class="trigger"> <a class="page-link" href="/archive/">Archive</a> <a class="page-link" href="/author/">Author</a> <a class="page-link" href="https://feeds.feedburner.com/jussijudin">RSS</a></div> </nav></div></header><div class="page-content"><div class="wrapper"><article class="post" itemscope="itemscope" itemtype="http://schema.org/BlogPosting"><meta itemprop="keywords" content="cpu-priority,nice,chrt"/> <span itemprop="publisher" itemscope="itemscope" itemtype="https://schema.org/Organization"> <span itemprop="logo" itemscope="itemscope" itemtype="https://schema.org/ImageObject"><meta itemprop="url" content="https://barro.github.io/icons/parruki-60x60.png"/><meta itemprop="width" content="60"/><meta itemprop="height" content="60"/> </span><meta itemprop="name" content="ParruKi blog"/> </span><meta itemprop="description" content="Making long-running CPU intensive processes not to suck every bit of CPU time from other processes in Linux."/><meta itemscope="itemscope" itemprop="mainEntityOfPage" itemType="https://schema.org/WebPage" itemid="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/"/> <header class="post-header"><h1 class="post-title" itemprop="name headline">Being a good CPU neighbor</h1><p class="post-meta"><time datetime="2016-02-28T18:00:05+02:00" itemprop="datePublished dateModified">Sunday, Feb 28, 2016</time> • <span itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"> <span itemprop="name">Jussi Judin</span> </span> • <a itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" href="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/id-cropped-800x400.png"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMBAMAAADWlCNiAAAAD1BMVEUAAADMKOTs0r8/xHM6t5nNaQqaAAAAAXRSTlMAQObYZgAAAEdJREFUeAFjYGAUFBRgYGBSUlJgYGA2NjZgcHFgYGBxIUMCKAqUUwIDoChQjmwJCFBSAFkDtgMkCpQjXQLqXIgdUOeCAekSAMsOHBixPtp3AAAAAElFTkSuQmCC" title="Article identicon" alt="Article identicon" width="48" height="12"/><meta itemprop="url" content="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/id-cropped-800x400.png"/><meta itemprop="width" content="800"/><meta itemprop="height" content="400"/> </a></p> </header><div class="post-content" itemprop="articleBody"><p>Very often computational tasks are roughly <a href="https://en.wikipedia.org/wiki/Processing_modes">divided</a> into <a href="https://en.wikipedia.org/wiki/Real-time_computing">real-time</a> and <a href="https://en.wikipedia.org/wiki/Batch_processing">batch processing</a> tasks. Sometimes you might want to run some tasks that take a large amount of computation resources, get the result as fast as possible, but you don’t really care exactly when you get the result out.</p><p>In larger organizations there are shared computers that usually have a lot of CPU power and memory available and that are mostly idle. But they are also used by other users that will be quite annoyed if they suffer from long delays to key presses or from similar issues because your batch processing tasks take all the resources that are available away from the system. Fortunately *nix systems provide different mechanisms available to non-root users to avoid these kind of issues.</p><p>These issue can also raise in situations where you have a system that can only allocate static resource requirements to tasks, like in <a href="https://jenkins-ci.org/">Jenkins</a>. As an example, you might have some test jobs that need to finish within certain time limit mixed with compilation jobs that should finish as soon as possible, but that can yield some resources to these higher priority test jobs, as they don’t have as strict time limitation requirements. And you usually don’t want to limit the resources that compilation jobs can use, if they are run on otherwise idle machine.</p><p>Here I’m specifically focusing on process priority settings and other CPU scheduling settings provided by Linux, as it currently happens to be probably the most used operating system kernel for multi-user systems. These settings affect how much CPU time a process gets relative to other processes and are especially useful on shared overloaded systems where there are more processes running than what there are CPU cores available.</p><h2 id="different-process-scheduling-priorities-in-linux">Different process scheduling priorities in Linux</h2><p>Linux and <a href="http://pubs.opengroup.org/onlinepubs/9699919799/">POSIX</a> interfaces provide different <a href="http://man7.org/linux/man-pages/man7/sched.7.html">scheduling policies</a> that define how <a href="https://www.kernel.org/doc/Documentation/scheduler/">Linux scheduler</a> allocates CPU time to a process. There are two main scheduling policies for processes: real-time priority policies and normal scheduling policies. Real-time policies are usually accessible only to root user and are not the point of interest of here, as they can not usually be used by normal users on shared systems.</p><p>At the time of the writing this article there are three normal scheduling policies available to normal users for process priorities:</p><ol><li><code class="highlighter-rouge">SCHED_OTHER</code>: the default scheduling policy in Linux with the default <a href="http://man7.org/linux/man-pages/man2/setpriority.2.html">dynamic priority</a> of 0.</li><li><code class="highlighter-rouge">SCHED_BATCH</code>: policy for scheduling batch processes. This schedules processes in similar fashion as <code class="highlighter-rouge">SCHED_OTHER</code> and is affected by the dynamic priority of a process. This makes the scheduler assume that the process is CPU intensive and makes it harder to wake up from a sleep.</li><li><code class="highlighter-rouge">SCHED_IDLE</code>: the lowest priority scheduling policy. Not affected by dynamic priorities. This equals to <a href="https://github.com/torvalds/linux/blob/v4.4/kernel/sched/core.c#L3860">nice level priority of 20</a>.</li></ol><p>The standard *nix way to change process priorities is to use <a href="http://man7.org/linux/man-pages/man1/nice.1.html"><code class="highlighter-rouge">nice</code></a> command. By default in Linux, process can get <a href="http://man7.org/linux/man-pages/man2/getpriority.2.html">nice values</a> of -20–19 where the default nice value for a process is 0. When process is started with <code class="highlighter-rouge">nice</code> command, the nice value will be</p><ol><li>Values 0–19 are available to a normal user and -20–-1 are available to the root user. The lowest priority nice value of 19 gives process <a href="https://www.kernel.org/doc/Documentation/scheduler/sched-nice-design.txt">5% of CPU time</a> with the default scheduler in Linux.</li></ol><p><a href="http://man7.org/linux/man-pages/man1/chrt.1.html"><code class="highlighter-rouge">chrt</code></a> command can be used to give a process access to <code class="highlighter-rouge">SCHED_BATCH</code> and <code class="highlighter-rouge">SCHED_IDLE</code> scheduling policies. <code class="highlighter-rouge">chrt</code> can be used with combination of <code class="highlighter-rouge">nice</code> command to lower the priority of <code class="highlighter-rouge">SCHED_BATCH</code> scheduling policy. And using <code class="highlighter-rouge">SCHED_IDLE</code> (= nice level 20) policy should give around 80% of the CPU time that nice level of 19 has, as nice level weights <a href="https://github.com/torvalds/linux/blob/v4.4/kernel/sched/sched.h#L1116">increase the process priority by 1.25 compared to lower priority level</a>.</p><h2 id="benchmarking-with-different-competing-workloads">Benchmarking with different competing workloads</h2><p>I wanted to benchmark the effect of different scheduling policies on a work done by a specific benchmark program. I used a system with Linux 3.17.0 kernel with <a href="http://ark.intel.com/products/65523/Intel-Core-i7-3770K-Processor-8M-Cache-up-to-3_90-GHz">Intel Core i7-3770K CPU at 3.5 GHz</a> processor with hyperthreading and frequency scaling turned on and 32 gigabytes of RAM. I didn’t manage to make the CPU frequency constant, so results vary a little between runs. I used John the Ripper’s bcrypt benchmark started with following command as the test program for useful work:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>/usr/sbin/john <span class="nt">--format</span><span class="o">=</span>bcrypt <span class="nt">-test</span>
</code></pre></div></div><p>I benchmarked 1 and 7 instances of John the Ripper for 9 iterations (9 * 5 = 45 seconds) with various amounts of non-benchmarking processes running at the same time. 1 benchmarking process should by default not have any cache contention resulting from other benchmarking processes happening and 7 benchmarking processes saturate all but 1 logical CPU core and can have cache and computational unit contention with each other.</p><p>Non-bechmarking processes were divided into different categories and there were 0–7 times CPU cores instances of them started to make them fight for CPU time with benchmarking processes. The results of running different amounts of non-benchmarking processes with different scheduling policies can be found from tables <a href="#cpu-looper-table-cpus-1">1</a>, <a href="#cpu-looper-table-cpus-7">2</a>, <a href="#mem-looper-table-cpus-1">3</a>, and <a href="#mem-looper-table-cpus-7">4</a>. Different scheduling policies visible in those tables are:</p><ul><li><em>default</em>: default scheduling policy. Command started without any wrappers. Corresponds to <code class="highlighter-rouge">SCHED_OTHER</code> with nice value of 0.</li><li><em>chrt-batch</em>: the default <code class="highlighter-rouge">SCHED_BATCH</code> scheduling policy. Command started with <code class="highlighter-rouge">chrt --batch 0</code> prefix.</li><li><em>nice 10</em>: <code class="highlighter-rouge">SCHED_OTHER</code> scheduling policy with the default nice value of 10. Command started with <code class="highlighter-rouge">nice</code> prefix.</li><li><em>nice 19</em>: <code class="highlighter-rouge">SCHED_OTHER</code> scheduling policy with nice value of 19. Command started with <code class="highlighter-rouge">nice -n 19</code> prefix. This should theoretically take around 5 % of CPU time out from the useful work.</li><li><em>nice 19 batch</em>: <code class="highlighter-rouge">SCHED_BATCH</code> scheduling policy with nice value of 19. Command started with <code class="highlighter-rouge">nice -n 19 chrt --batch 0</code> prefix.</li><li><em>sched idle</em>: <code class="highlighter-rouge">SCHED_IDLE</code> scheduling policy. Command started with <code class="highlighter-rouge">chrt --idle 0</code> prefix. This should theoretically take around 80 % of CPU time compared to nice level 19 out from useful work.</li></ul><p>The results in those tables reflect the relative average percentage of work done compared to the situation when there are no additional processes disturbing the benchmark. These only show the average value and do not show, for example, variance that could be useful to determine how close those values are of each other. You can download get the raw benchmarking data and the source code to generate and analyze this data from following links:</p><ul><li><a href="cpu-neighbor-source-code.tar.xz">Source code for test programs and generating and analyzing the data</a></li><li><a href="cpu-neighbor-benchmarks.tar.xz">Raw benchmarking data</a></li></ul><h3 id="cpu-looper">CPU looper</h3><p>CPU looper applications consists purely of an application that causes CPU load. Its main purpose is just to test the scheduling policies without forcing <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU cache</a> misses. Of course there will be <a href="https://en.wikipedia.org/wiki/CPU_cache">context switches</a> that can replace data cache entries related to <a href="https://en.wikipedia.org/wiki/Context_(computing)">process state</a> and instruction cache entries for the process with another, but there won’t be any extra intentional cache flushing happening here.</p><p>The actual CPU looper application consists code shown in <a href="#cpu-neighbor-figure-1">figure 1</a> compiled without any optimizations:</p><figure id="cpu-neighbor-figure-1"><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div><figcaption>Figure 1: source code for CPU looper program.</figcaption> </figure><p>The results for starting 0–7 times CPU cores of CPU looper processes with the default priority and then running benchmark with 1 or 7 cores can be found from tables <a href="#cpu-looper-table-cpus-1">1</a> and <a href="#cpu-looper-table-cpus-7">2</a>.</p><figure id="cpu-looper-table-cpus-1"><table style="margin:0 auto"><thead><tr><th style="text-align:left">1 worker</th><th style="text-align:right">0</th><th style="text-align:right">1</th><th style="text-align:right">2</th><th style="text-align:right">3</th><th style="text-align:right">4</th><th style="text-align:right">5</th><th style="text-align:right">6</th><th style="text-align:right">7</th></tr></thead><tbody><tr><td style="text-align:left"><em>default</em></td><td style="text-align:right">100</td><td style="text-align:right">64.6</td><td style="text-align:right">36.4</td><td style="text-align:right">25.5</td><td style="text-align:right">18.2</td><td style="text-align:right">15.4</td><td style="text-align:right">12.5</td><td style="text-align:right">11.0</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched batch</em></td><td style="text-align:right">100</td><td style="text-align:right">66.5</td><td style="text-align:right">37.0</td><td style="text-align:right">24.0</td><td style="text-align:right">16.3</td><td style="text-align:right">14.8</td><td style="text-align:right">12.2</td><td style="text-align:right">10.9</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 10</em></td><td style="text-align:right">100</td><td style="text-align:right">93.3</td><td style="text-align:right">90.2</td><td style="text-align:right">82.7</td><td style="text-align:right">75.4</td><td style="text-align:right">75.2</td><td style="text-align:right">75.0</td><td style="text-align:right">74.9</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">92.9</td><td style="text-align:right">90.4</td><td style="text-align:right">91.0</td><td style="text-align:right">91.8</td><td style="text-align:right">89.8</td><td style="text-align:right">89.4</td><td style="text-align:right">90.9</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">94.0</td><td style="text-align:right">89.2</td><td style="text-align:right">91.4</td><td style="text-align:right">89.8</td><td style="text-align:right">86.4</td><td style="text-align:right">89.4</td><td style="text-align:right">90.7</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>95.0</strong></td><td style="text-align:right"><strong>91.3</strong></td><td style="text-align:right"><strong>92.2</strong></td><td style="text-align:right"><strong>92.0</strong></td><td style="text-align:right"><strong>92.6</strong></td><td style="text-align:right"><strong>91.0</strong></td><td style="text-align:right"><strong>92.4</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">80.0</td><td style="text-align:right">74.7</td><td style="text-align:right">68.0</td><td style="text-align:right">67.7</td><td style="text-align:right">67.5</td><td style="text-align:right">64.5</td><td style="text-align:right">60.7</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>92.5</strong></td><td style="text-align:right">83.8</td><td style="text-align:right">75.9</td><td style="text-align:right">75.0</td><td style="text-align:right">74.3</td><td style="text-align:right">74.1</td><td style="text-align:right">69.8</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right">89.8</td><td style="text-align:right"><strong>89.7</strong></td><td style="text-align:right"><strong>90.9</strong></td><td style="text-align:right"><strong>89.0</strong></td><td style="text-align:right"><strong>87.8</strong></td><td style="text-align:right"><strong>87.4</strong></td><td style="text-align:right"><strong>87.2</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 19</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>77.9</strong></td><td style="text-align:right"><strong>69.7</strong></td><td style="text-align:right"><strong>66.9</strong></td><td style="text-align:right"><strong>66.3</strong></td><td style="text-align:right"><strong>64.6</strong></td><td style="text-align:right"><strong>63.4</strong></td><td style="text-align:right"><strong>58.1</strong></td></tr></tbody></table><figcaption>Table 1: the relative percentage of average work done for one benchmarking worker when there are 0–7 times the logical CPU cores of non-benchmarking CPU hogging jobs running with different scheduling policies.</figcaption> </figure><figure id="cpu-looper-table-cpus-7"><table style="margin:0 auto"><thead><tr><th style="text-align:left">7 workers</th><th style="text-align:right">0</th><th style="text-align:right">1</th><th style="text-align:right">2</th><th style="text-align:right">3</th><th style="text-align:right">4</th><th style="text-align:right">5</th><th style="text-align:right">6</th><th style="text-align:right">7</th></tr></thead><tbody><tr><td style="text-align:left"><em>default</em></td><td style="text-align:right">100</td><td style="text-align:right">49.8</td><td style="text-align:right">33.6</td><td style="text-align:right">24.6</td><td style="text-align:right">19.4</td><td style="text-align:right">16.4</td><td style="text-align:right">13.8</td><td style="text-align:right">12.2</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched batch</em></td><td style="text-align:right">100</td><td style="text-align:right">51.1</td><td style="text-align:right">34.0</td><td style="text-align:right">25.1</td><td style="text-align:right">20.0</td><td style="text-align:right">16.6</td><td style="text-align:right">14.2</td><td style="text-align:right">12.4</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 10</em></td><td style="text-align:right">100</td><td style="text-align:right">92.9</td><td style="text-align:right">87.2</td><td style="text-align:right">80.1</td><td style="text-align:right">75.0</td><td style="text-align:right">71.0</td><td style="text-align:right">66.3</td><td style="text-align:right">61.1</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">94.1</td><td style="text-align:right">94.9</td><td style="text-align:right">95.4</td><td style="text-align:right">95.2</td><td style="text-align:right">96.2</td><td style="text-align:right"><strong>95.7</strong></td><td style="text-align:right">96.0</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">95.7</td><td style="text-align:right">95.2</td><td style="text-align:right">95.7</td><td style="text-align:right">95.5</td><td style="text-align:right">95.2</td><td style="text-align:right">94.6</td><td style="text-align:right">95.4</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>96.3</strong></td><td style="text-align:right"><strong>95.7</strong></td><td style="text-align:right"><strong>96.2</strong></td><td style="text-align:right"><strong>95.6</strong></td><td style="text-align:right"><strong>96.7</strong></td><td style="text-align:right">95.4</td><td style="text-align:right"><strong>96.7</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">93.6</td><td style="text-align:right">84.9</td><td style="text-align:right">78.0</td><td style="text-align:right">71.4</td><td style="text-align:right">65.7</td><td style="text-align:right">60.4</td><td style="text-align:right">56.2</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">92.4</td><td style="text-align:right">84.1</td><td style="text-align:right">77.6</td><td style="text-align:right">69.9</td><td style="text-align:right">65.6</td><td style="text-align:right">60.7</td><td style="text-align:right">56.4</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>95.5</strong></td><td style="text-align:right"><strong>94.9</strong></td><td style="text-align:right"><strong>94.5</strong></td><td style="text-align:right"><strong>93.9</strong></td><td style="text-align:right"><strong>94.3</strong></td><td style="text-align:right"><strong>93.7</strong></td><td style="text-align:right"><strong>91.9</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 19</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>91.4</strong></td><td style="text-align:right"><strong>80.9</strong></td><td style="text-align:right"><strong>71.4</strong></td><td style="text-align:right"><strong>64.3</strong></td><td style="text-align:right"><strong>58.3</strong></td><td style="text-align:right"><strong>52.5</strong></td><td style="text-align:right"><strong>48.5</strong></td></tr></tbody></table><figcaption>Table 2: the relative percentage of average work done for seven benchmarking workers when there are 0–7 times the logical CPU cores of non-benchmarking CPU hogging jobs running with different scheduling policies.</figcaption> </figure><p>Tables <a href="#cpu-looper-table-cpus-1">1</a> and <a href="#cpu-looper-table-cpus-7">2</a> show that the effect is not consistent between different scheduling policies and when there is 1 benchmarking worker running it suffers more from the lower priority processes than what happens when there are 7 benchmarking workers running. But with higher priority scheduling policies for background processes the average amount of work done for 1 process remains higher for light loads than with 7 worker processes. These discrepancies can be probably explained by how hyperthreading works by sharing the same physical CPU cores and by caching issues.</p><h3 id="memory-looper">Memory looper</h3><p>Processors nowadays have multiple levels of cache and no cache isolation and memory access from one core can <a href="https://www.youtube.com/watch?v=QBu2Ae8-8LM#t=41m14s">wreak havoc for other cores</a> with just moving data from and to memory. So I wanted to see what happens with different scheduling policies when running multiple instances of a simple program that run on the background when John the Ripper is trying to do some real work.</p><figure id="cpu-neighbor-figure-2"><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;stdlib.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// 2 * 20 megabytes should be enough to spill all caches.
</span>    <span class="k">const</span> <span class="kt">size_t</span> <span class="n">data_size</span> <span class="o">=</span> <span class="mi">20000000</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">size_t</span> <span class="n">items</span> <span class="o">=</span> <span class="n">data_size</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">long</span><span class="p">);</span>
    <span class="kt">long</span><span class="o">*</span> <span class="n">area_source</span> <span class="o">=</span> <span class="n">calloc</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">long</span><span class="p">));</span>
    <span class="kt">long</span><span class="o">*</span> <span class="n">area_target</span> <span class="o">=</span> <span class="n">calloc</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">long</span><span class="p">));</span>
    <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Just do some memory operations that access the whole memory area.
</span>        <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">items</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">area_source</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">area_target</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">items</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">area_target</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^=</span> <span class="n">area_source</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div><figcaption>Figure 2: source code for memory bandwidth hogging program.</figcaption> </figure><p>Program shown in <a href="#cpu-neighbor-figure-2">figure 2</a> is compiled without any optimizations and it basically reads one word from memory, adds 1 to it and stores the result to some other memory area and then <a href="https://en.wikipedia.org/wiki/Exclusive_or">XORs</a> the read memory area with the written memory area. So it basically does not do anything useful, but reads and writes a lot of data into memory every time the program gets some execution time.</p><p>Tables <a href="#mem-looper-table-cpus-1">3</a> and <a href="#mem-looper-table-cpus-7">4</a> show the relative effect on John the Ripper benchmarking program when there are various amounts of the program shown in <a href="#cpu-neighbor-figure-2">figure 2</a> running at the same time. If you compare these numbers to values shown in tables <a href="#cpu-looper-table-cpus-1">1</a> and <a href="#cpu-looper-table-cpus-7">2</a> a program that only uses CPU cycles is running, the numbers for useful work can be in some cases around 10 percentage points lower. So there is apparently some cache contention ongoing with this benchmarking program and the effect of lower priority scheduling policies is not the same that could be theoretically expected just from the allocated time slices.</p><figure id="mem-looper-table-cpus-1"><table><thead><tr><th style="text-align:left">1 worker</th><th style="text-align:right">0</th><th style="text-align:right">1</th><th style="text-align:right">2</th><th style="text-align:right">3</th><th style="text-align:right">4</th><th style="text-align:right">5</th><th style="text-align:right">6</th><th style="text-align:right">7</th></tr></thead><tbody><tr><td style="text-align:left"><em>default priority</em></td><td style="text-align:right">100</td><td style="text-align:right">61.7</td><td style="text-align:right">32.6</td><td style="text-align:right">21.8</td><td style="text-align:right">16.6</td><td style="text-align:right">13.3</td><td style="text-align:right">11.2</td><td style="text-align:right">9.8</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched batch</em></td><td style="text-align:right">100</td><td style="text-align:right">60.2</td><td style="text-align:right">32.6</td><td style="text-align:right">22.7</td><td style="text-align:right">16.2</td><td style="text-align:right">12.9</td><td style="text-align:right">10.9</td><td style="text-align:right">10.2</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 10</em></td><td style="text-align:right">100</td><td style="text-align:right">85.2</td><td style="text-align:right">82.1</td><td style="text-align:right">75.8</td><td style="text-align:right">70.8</td><td style="text-align:right">69.6</td><td style="text-align:right">70.5</td><td style="text-align:right">68.1</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>85.4</strong></td><td style="text-align:right"><strong>83.0</strong></td><td style="text-align:right">79.7</td><td style="text-align:right">81.7</td><td style="text-align:right">78.2</td><td style="text-align:right">81.9</td><td style="text-align:right"><strong>84.7</strong></td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">83.8</td><td style="text-align:right">81.2</td><td style="text-align:right">80.5</td><td style="text-align:right"><strong>83.4</strong></td><td style="text-align:right">80.4</td><td style="text-align:right">79.4</td><td style="text-align:right">84.3</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right">82.9</td><td style="text-align:right">80.9</td><td style="text-align:right"><strong>81.2</strong></td><td style="text-align:right">82.1</td><td style="text-align:right"><strong>80.6</strong></td><td style="text-align:right"><strong>82.3</strong></td><td style="text-align:right">81.8</td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">80.0</td><td style="text-align:right">74.7</td><td style="text-align:right">68.0</td><td style="text-align:right">67.7</td><td style="text-align:right">67.5</td><td style="text-align:right">64.5</td><td style="text-align:right">60.7</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">80.8</td><td style="text-align:right">74.1</td><td style="text-align:right">67.6</td><td style="text-align:right">67.1</td><td style="text-align:right">67.9</td><td style="text-align:right">65.5</td><td style="text-align:right">63.3</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>83.9</strong></td><td style="text-align:right"><strong>81.6</strong></td><td style="text-align:right"><strong>79.2</strong></td><td style="text-align:right"><strong>77.0</strong></td><td style="text-align:right"><strong>75.9</strong></td><td style="text-align:right"><strong>76.8</strong></td><td style="text-align:right"><strong>77.1</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 19</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>77.9</strong></td><td style="text-align:right"><strong>69.7</strong></td><td style="text-align:right"><strong>66.9</strong></td><td style="text-align:right"><strong>66.3</strong></td><td style="text-align:right"><strong>64.6</strong></td><td style="text-align:right"><strong>63.4</strong></td><td style="text-align:right"><strong>58.1</strong></td></tr><tr><td style="text-align:left"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr></tbody></table><figcaption>Table 3: the relative percentage of average work done for one benchmarking worker when there are 0–7 times the logical CPU cores of non-benchmarking CPU and memory bandwidth hogging jobs running with different scheduling policies.</figcaption> </figure><figure id="mem-looper-table-cpus-7"><table><thead><tr><th style="text-align:left">7 workers</th><th style="text-align:right">0</th><th style="text-align:right">1</th><th style="text-align:right">2</th><th style="text-align:right">3</th><th style="text-align:right">4</th><th style="text-align:right">5</th><th style="text-align:right">6</th><th style="text-align:right">7</th></tr></thead><tbody><tr><td style="text-align:left"><em>default</em></td><td style="text-align:right">100</td><td style="text-align:right">48.4</td><td style="text-align:right">32.6</td><td style="text-align:right">24.5</td><td style="text-align:right">19.7</td><td style="text-align:right">16.3</td><td style="text-align:right">14.2</td><td style="text-align:right">12.3</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched batch</em></td><td style="text-align:right">100</td><td style="text-align:right">48.6</td><td style="text-align:right">32.2</td><td style="text-align:right">23.7</td><td style="text-align:right">19.4</td><td style="text-align:right">16.2</td><td style="text-align:right">14.0</td><td style="text-align:right">12.6</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 10</em></td><td style="text-align:right">100</td><td style="text-align:right">89.3</td><td style="text-align:right">81.5</td><td style="text-align:right">74.6</td><td style="text-align:right">69.2</td><td style="text-align:right">64.6</td><td style="text-align:right">60.4</td><td style="text-align:right">56.3</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">92.0</td><td style="text-align:right">90.5</td><td style="text-align:right">90.4</td><td style="text-align:right">91.2</td><td style="text-align:right">91.3</td><td style="text-align:right">90.6</td><td style="text-align:right">90.5</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">91.5</td><td style="text-align:right">91.8</td><td style="text-align:right"><strong>92.5</strong></td><td style="text-align:right"><strong>91.8</strong></td><td style="text-align:right">91.9</td><td style="text-align:right">92.1</td><td style="text-align:right">91.9</td></tr><tr><td style="text-align:left"><em>nice 0</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>92.1</strong></td><td style="text-align:right"><strong>91.9</strong></td><td style="text-align:right">91.9</td><td style="text-align:right">91.5</td><td style="text-align:right"><strong>92.0</strong></td><td style="text-align:right"><strong>92.4</strong></td><td style="text-align:right"><strong>92.1</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19</em></td><td style="text-align:right">100</td><td style="text-align:right">85.4</td><td style="text-align:right">77.3</td><td style="text-align:right">70.4</td><td style="text-align:right">63.3</td><td style="text-align:right">58.3</td><td style="text-align:right">54.2</td><td style="text-align:right">50.3</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>nice 19 batch</em></td><td style="text-align:right">100</td><td style="text-align:right">86.8</td><td style="text-align:right">77.7</td><td style="text-align:right">70.0</td><td style="text-align:right">63.4</td><td style="text-align:right">58.8</td><td style="text-align:right">54.4</td><td style="text-align:right">50.6</td></tr><tr><td style="text-align:left"><em>nice 10</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>90.6</strong></td><td style="text-align:right"><strong>89.0</strong></td><td style="text-align:right"><strong>88.9</strong></td><td style="text-align:right"><strong>88.9</strong></td><td style="text-align:right"><strong>88.0</strong></td><td style="text-align:right"><strong>87.4</strong></td><td style="text-align:right"><strong>86.3</strong></td></tr><tr><td style="text-align:left">—  </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr><tr><td style="text-align:left"><em>nice 19</em> vs. <em>sched idle</em></td><td style="text-align:right">100</td><td style="text-align:right"><strong>82.8</strong></td><td style="text-align:right"><strong>72.9</strong></td><td style="text-align:right"><strong>62.9</strong></td><td style="text-align:right"><strong>57.3</strong></td><td style="text-align:right"><strong>52.2</strong></td><td style="text-align:right"><strong>48.2</strong></td><td style="text-align:right"><strong>44.1</strong></td></tr><tr><td style="text-align:left"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td><td style="text-align:right"> </td></tr></tbody></table><figcaption>Table 4: the relative percentage of average work done for seven benchmarking workers when there are 0–7 times the logical CPU cores of non-benchmarking CPU and memory bandwidth hogging jobs running with different scheduling policies.</figcaption> </figure><h2 id="conclusions">Conclusions</h2><p>These are just results of one specific benchmark with two specific workloads on one specific machine with 4 hyperthreaded CPU cores. They should anyways give you some kind of an idea how different CPU scheduling policies under Linux affect the load that you do not want to disturb when your machine is more or less overloaded. Clearly when you are reading and writing data from and to memory, the lower priority background process has bigger impact on the actual worker process than what the allocated time slices would predict. But, unsurprisingly, a single user can have quite a large impact on how much their long running CPU hogging processes affect rest of the machine.</p><p>I did not do any investigation how much work those processes that are supposed to disturb the benchmarking get done. In this case <code class="highlighter-rouge">SCHED_BATCH</code> with nice value of 19 could probably be the best scheduling policy if we want to get the most work done and at the same time avoid disturbing other users. Otherwise, it looks like the <code class="highlighter-rouge">SCHED_IDLE</code> policy, taken into use with <code class="highlighter-rouge">chrt --idle 0</code> command, that is promised to have the lowest impact on other processes has the lowest impact. Especially when considering processes started with lower nice values than the default one.</p></div></article><div id="disqus_thread"></div> <script>var disqus_config=function(){this.page.url="https://barro.github.io/2016/02/being-a-good-cpu-neighbor/",this.page.identifier="/2016/02/being-a-good-cpu-neighbor"};!function(){var e=document,i=e.createElement("script");i.src="//barro.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)}()</script></div></div><footer class="site-footer"><div class="wrapper"><h2 class="footer-heading">Jussi Judin's weblog</h2><div class="footer-col-wrapper"><div class="footer-col footer-col-1"><ul class="contact-list"><li>Jussi Judin</li><li>jju<span>din</span>+github <span>AT</span> iki DOT <span>f</span>i</li></ul></div><div class="footer-col footer-col-2"><ul class="social-media-list"><li> <a href="https://github.com/barro" title="Barro">GitHub</a></li><li> <a href="https://bitbucket.org/barro" title="barro">Bitbucket</a></li><li> <a href="https://facebook.com/b4rr0" title="B4rr0">Facebook</a></li><li> <a href="https://twitter.com/B4rr0" title="@B4rr0">Twitter</a></li><li> <a href="https://plus.google.com/+JussiJudin-jj/" title="+JussiJudin-jj">Google+</a></li></ul></div><div class="footer-col footer-col-3"><p>Programming related topics. Maybe even some original content!</p></div></div></div></footer><script>!function(e,a,t,n,c,o,s){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,o=a.createElement(t),s=a.getElementsByTagName(t)[0],o.async=1,o.src=n,s.parentNode.insertBefore(o,s)}(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","UA-71880517-1","auto"),ga("send","pageview")</script></body></html>