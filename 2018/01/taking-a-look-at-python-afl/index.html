<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>Taking a look at python-afl</title><meta name="description" content="Taking a look at fuzzing Python programs with python-afl and its performance."/><link rel="stylesheet" href="/css/main.css"/><link rel="canonical" href="https://barro.github.io/2018/01/taking-a-look-at-python-afl/"/><link rel="alternate" type="application/rss+xml" title="Jussi Judin's weblog" href="https://feeds.feedburner.com/jussijudin"/><link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon-180x180.png"/><link rel="icon" type="image/png" href="/icons/favicon-32x32.png" sizes="32x32"/><link rel="icon" type="image/png" href="/icons/android-chrome-192x192.png" sizes="192x192"/><link rel="icon" type="image/png" href="/icons/favicon-96x96.png" sizes="96x96"/><link rel="icon" type="image/png" href="/icons/favicon-16x16.png" sizes="16x16"/><link rel="manifest" href="/icons/manifest.json"/><link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#00a300"/><meta name="msapplication-TileImage" content="/icons/mstile-144x144.png"/><meta name="theme-color" content="#ffffff"/><meta content="928229747232422" property="fb:app_id"/><meta content="Jussi Judin's weblog" property="og:site_name"/><meta content="Taking a look at python-afl" property="og:title"/><meta content="article" property="og:type"/><meta content="Taking a look at fuzzing Python programs with python-afl and its performance." property="og:description"/><meta content="https://barro.github.io/2018/01/taking-a-look-at-python-afl/" property="og:url"/><meta content="2018-01-07T18:00:08+02:00" property="article:published_time"/><meta content="https://barro.github.io/author/" property="article:author"/><meta property="og:image" content="https://barro.github.io/2018/01/taking-a-look-at-python-afl/id-cropped-800x400.png"/><meta content="python-afl" property="article:tag"/><meta content="afl" property="article:tag"/><meta content="afl-fuzz" property="article:tag"/><meta content="fuzzing" property="article:tag"/><meta content="python" property="article:tag"/><meta content="benchmark" property="article:tag"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="@b4rr0"/><meta name="twitter:creator" content="@b4rr0"/><meta name="twitter:title" content="Taking a look at python-afl"/><meta name="twitter:url" content="https://barro.github.io/2018/01/taking-a-look-at-python-afl/"/><meta name="twitter:description" content="Taking a look at fuzzing Python programs with python-afl and its performance."/><meta name="twitter:image:src" content="https://barro.github.io/2018/01/taking-a-look-at-python-afl/id-square-400x400.png"/></head><body><header class="site-header"><div class="wrapper"><a class="site-title" href="/">Jussi Judin's weblog</a><nav class="site-nav"> <a href="#" class="menu-icon"> <svg viewBox="0 0 18 15"> <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/> <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/> <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/> </svg> </a><div class="trigger"> <a class="page-link" href="/archive/">Archive</a> <a class="page-link" href="/author/">Author</a> <a class="page-link" href="https://feeds.feedburner.com/jussijudin">RSS</a></div> </nav></div></header><div class="page-content"><div class="wrapper"><article class="post" itemscope="itemscope" itemtype="http://schema.org/BlogPosting"><meta itemprop="keywords" content="python-afl,afl,afl-fuzz,fuzzing,python,benchmark"/> <span itemprop="publisher" itemscope="itemscope" itemtype="https://schema.org/Organization"> <span itemprop="logo" itemscope="itemscope" itemtype="https://schema.org/ImageObject"><meta itemprop="url" content="https://barro.github.io/icons/parruki-60x60.png"/><meta itemprop="width" content="60"/><meta itemprop="height" content="60"/> </span><meta itemprop="name" content="ParruKi blog"/> </span><meta itemprop="description" content="Taking a look at fuzzing Python programs with python-afl and its performance."/><meta itemscope="itemscope" itemprop="mainEntityOfPage" itemType="https://schema.org/WebPage" itemid="https://barro.github.io/2018/01/taking-a-look-at-python-afl/"/> <header class="post-header"><h1 class="post-title" itemprop="name headline">Taking a look at python-afl</h1><p class="post-meta"><time datetime="2018-01-07T18:00:08+02:00" itemprop="datePublished dateModified">Sunday, Jan 7, 2018</time> • <span itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"> <span itemprop="name">Jussi Judin</span> </span> • <a itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" href="https://barro.github.io/2018/01/taking-a-look-at-python-afl/id-cropped-800x400.png"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAIAAACr2KkGAAAABnRSTlMAAAAAAABupgeRAAAARklEQVR4AWNY4bCNIGKgIxh1EPEAjzuafpZBEFwErxRh0HKgGg0RctCog2iYhvz+hqAhTHfgcSLxDhp1EKaiAcn2ow4iBAC39y205cofNAAAAABJRU5ErkJggg==" title="Article identicon" alt="Article identicon" width="48" height="12"/><meta itemprop="url" content="https://barro.github.io/2018/01/taking-a-look-at-python-afl/id-cropped-800x400.png"/><meta itemprop="width" content="800"/><meta itemprop="height" content="400"/> </a></p> </header><div class="post-content" itemprop="articleBody"><p>I have been using <a href="http://lcamtuf.coredump.cx/afl/">american fuzzy lop</a> to <a href="https://en.wikipedia.org/wiki/Fuzzing">fuzz</a> various C and C++ programs and libraries. It is a wonderfully fast fuzzer that is generally easy to get started with and it usually finds new bugs in programs that have not been fuzzed previously. Support for american fuzzy lop instrumentation has also been added for other languages and I decided to try out how it works with <a href="https://www.python.org/">Python</a>. More specifically with the reference CPython implementation of it.</p><h2 id="fuzzing-python-programs-with-american-fuzzy-lop">Fuzzing Python programs with american fuzzy lop</h2><p>American fuzzy lop generally works by running a program that is compiled with american fuzzy lop instrumentation built in. It executes the program with <em>afl-fuzz</em> command that modifies the input data that is fed to the program, monitors how the program behaves, and registers everything that causes abnormal program behavior. This works well for natively compiled programs, but causes various issues with interpreted programs.</p><p>Python is by default an interpreted language, so to execute Python programs, you need to start a Python interpreter before executing your code. This means that if you would instrument the Python interpreter with american fuzzy lop instrumentation and run the interpreter with <em>afl-fuzz</em>, it would mostly fuzz the inner workings of the interpreter, not the actual Python program.</p><p>Fortunately there is <a href="https://github.com/jwilk/python-afl">python-afl</a> module that enables american fuzzy lop instrumentation for just the Python code instead of instrumenting the Python interpreter. In native programs american fuzzy lop compiler wrapper (<em>afl-gcc</em>, <em>afl-clang</em>, <em>afl-clang-fast</em>) adds the necessary instrumentation and the connection to <em>afl-fuzz</em>. Python-afl is, however, designed in such way that it doesn’t try to wrap the whole program, but requires you to create a wrapper module that initializes fuzzing.</p><p>The most simple way to wrap a Python program with python-afl is to initialize python-afl and then run the program (assuming that <code class="highlighter-rouge">main()</code> function exists):</p><div id="instrumentation-pre-init" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">fuzzable_module</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
</code></pre></div></div><p>This script, saved to <code class="highlighter-rouge">fuzz-wrapper.py</code>, can be then run with <em>py-afl-fuzz</em> command that wraps <em>afl-fuzz</em> for Python programs:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>py-afl-fuzz <span class="nt">-m</span> 400 <span class="nt">-i</span> initial-inputs/ <span class="nt">-o</span> fuzzing-results/ <span class="nt">--</span> <span class="se">\</span>
    python fuzz-wrapper.py @@
</code></pre></div></div><p>More details about these command line switches can be found from <a href="http://lcamtuf.coredump.cx/afl/README.txt">AFL readme file</a>. This then brings out the famous <a href="http://lcamtuf.coredump.cx/afl/status_screen.txt">american fuzzy lop status screen</a>, but now for Python programs:</p><div class="text-center"> <figure class="inline-figure" id="figure-afl-status"> <a href="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen.html"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-736.webp 736w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-920.webp 920w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1104.webp 1104w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1472.webp 1472w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2208.webp 2208w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2900.webp 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/> <source type="image/png" srcset="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-736.png 736w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-920.png 920w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1104.png 1104w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1472.png 1472w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2208.png 2208w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2900.png 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/><img src="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-736.png" alt="afl-fuzz status screen with python-afl. Yes, I use white background." title="afl-fuzz status screen with python-afl. Yes, I use white background." width="736" height="441" class="figure-image"/></picture> </a><figcaption><p>Figure 1: <em>afl-fuzz</em> status screen with python-afl. Yes, I use white background.</p> </figcaption> </figure></div><p>Next sections will explain in more details how to make fuzzing these programs more efficient and what pitfalls there could be in Python programs from fuzzing efficiency point of view.</p><h3 id="afl-fuzz-modes-and-their-python-afl-equivalents">Afl-fuzz modes and their python-afl equivalents</h3><p>Generally <em>afl-fuzz</em> provides 4 fuzzing modes that differ in how the program execution between different fuzzing inputs behaves:</p><ul><li><span id="afl-dumb-mode">Dumb mode that just executes the program by doing <a href="http://man7.org/linux/man-pages/man2/fork.2.html"><code class="highlighter-rouge">fork()</code></a> and <a href="http://man7.org/linux/man-pages/man3/exec.3.html"><code class="highlighter-rouge">execv()</code></a>. This is the slowest mode that does not rely on any fancy tricks to speed up program execution and also does not provide any insights how the program behaves with different inputs. </span></li><li>Basic <a href="http://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html">fork server mode</a> where the fuzzed binary does all the initialization steps that happen before calling the <a href="http://en.cppreference.com/w/cpp/language/main_function"><code class="highlighter-rouge">main()</code> function</a> and then program is repeatedly forked from that point on. This also includes instrumentation that is compiled in to the program so there already is some insight on what is happening inside the program when a specific input is processed. There exists QEMU mode for <em>afl-fuzz</em> that technically enables fork server mode for uninstrumented binaries, but with some performance penalty.</li><li><a href="https://github.com/mirrorer/afl/tree/master/llvm_mode">Deferred instrumentation</a> that works in similar fashion as the basic fork server mode. Instead forking just before calling <code class="highlighter-rouge">main()</code> function, this enables to move the fork point further down the line and enables heavy program initialization steps to be avoided if they can be executed independently of the input.</li><li><a href="https://lcamtuf.blogspot.fi/2015/06/new-in-afl-persistent-mode.html">Persistent mode</a> where the fuzzable part of the program is repeatedly executed without resetting the program memory every time the program is called. This only works in practice if the program does not have a modifiable global state that can not be reset to the previous state.</li></ul><p><em>Afl-fuzz</em> generates new inputs and analyzes the program execution results roughly at the same speed regardless of the mode. So these modes are in the order of efficiency in a sense that how much overhead there is for fuzzing one input. They are also in the order of complexity on how easy they are to integrate into an existing program that has not been made to be fuzzed. Especially as the fastest modes require <a href="http://clang.llvm.org/">clang</a> to be available as a compiler and the fuzzable program needs to be able to be compiled and linked with it.</p><p>Python-afl, fortunately, provides equivalent modes without having to use special tools. These are also very fast to try out, as you don’t need to compile Python programs from scratch.</p><p>The dumb mode would be just equivalent of running Python interpreter directly with <em>afl-fuzz</em> without any instrumentation, so we will skip over it. The more interesting part is to use the deferred instrumentation. The code in the introductory section called <code class="highlighter-rouge">afl.init()</code> before the fuzzable module was imported. This is the most safe approach, as the fuzz target might do something with the input at import time. But more realistically, Python programs generally only call <code class="highlighter-rouge">import</code> statements, possibly conditionally, during the start-up and don’t handle any user provided data yet. So in this case, we can do imports first and move the <code class="highlighter-rouge">afl.init()</code> function just before where the actual work happens:</p><div id="instrumentation-deferred" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
</code></pre></div></div><p>We can gain some speed-ups with this by calling <code class="highlighter-rouge">os._exit()</code> function instead of letting Python to exit in the usual fashion where all the destructors and other functions that are called at exit:</p><div id="instrumentation-os-exit" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>Previous examples assume that the input file generated by the fuzzer comes as the first parameter on the command line. This is quite a good assumption, as many data processing modules for Python include a command line interface where they read and process files given on the command line. But if we can directly call the data processing function, we can instead use the standard input to feed the data:</p><div id="instrumentation-os-exit-stdin" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span><span class="p">,</span> <span class="n">sys</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>With Python 3 comes additional complexity. Python 3 processes the standard input using the encoding specified in the environment. Often in Unix environments it is UTF-8. As <em>afl-fuzz</em> mostly does bit manipulation, input is going to end up with broken UTF-8 data and results in exception when reading from the standard input file object. To work around this, you can use <code class="highlighter-rouge">sys.stdin.buffer</code> instead of <code class="highlighter-rouge">sys.stdin</code> in Python 3 based programs. Or create a shim that always results in raw bytes:</p><div id="instrumentation-stdin-python23" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span><span class="p">,</span> <span class="n">sys</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Python 3:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="nb">buffer</span>
<span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
    <span class="c"># There is no buffer attribute in Python 2:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>The fastest persistent mode requires that the program should not have a global state where the previous program execution affects the next one. There unfortunately is a surprising amount of global state in Python programs. It is not that uncommon to initialize some specific variables only during the program execution and then re-use the results later. This usually is harmless, but negatively affects the program stability that <em>afl-fuzz</em> is going to show in its status screen.</p><p>Persistent mode code for a fuzzable program could look like following including the learnings from the deferred instrumentation and its speedups:</p><div id="instrumentation-persistent" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Python 3:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="nb">buffer</span>
<span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
    <span class="c"># There is no buffer attribute in Python 2:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span>

<span class="k">while</span> <span class="n">afl</span><span class="o">.</span><span class="n">loop</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><h4 id="persistent-mode-stability">Persistent mode stability</h4><blockquote><p>This section has been added 6 months after writing the original article when Jakub Wilk pointed out potential stability issues with the original persistent mode code example on OS X and FreeBSD.</p></blockquote><p>Some systems where Python runs implement file manipulation by using buffered functions. The most prominent operating system where <em>afl-fuzz</em> runs that uses buffered I/O in Python is OS X/macOS and using the <a href="#instrumentation-persistent">persistent mode example in the previous section</a> does not work in Python 2 on these systems. It shows up as a low stability percentage in <em>afl-fuzz</em> user interface that means that the same input from <em>afl-fuzz</em> perspective leads program taking different paths between subsequent executions, as the input read by the program is not the same as what <em>afl-fuzz</em> has provided.</p><p>Buffered reads from a file work by calling low level file reading system calls with a moderately sized input buffer. This input buffer then makes sure that if we do a lot of small file system reads, like reading frame based data formats frame by frame, they will not result in as many system calls as they would result without buffering. This generally increases program performance, as programmers can rely on file system functions to work relatively fast even with non-optimal access patterns.</p><p>You need to set the stream position to the beginning when using persistent mode with <em>afl-fuzz</em> on systems that use buffered I/O and you are reading from the standard input. All these examples read data from the standard input, as it is generally more efficient than opening a new file for each fuzzing iteration. Rewinding the stream position to the beginning by using <a href="https://docs.python.org/2/tutorial/inputoutput.html#methods-of-file-objects">file.seek(0) method</a>.</p><p>Unfortunately not all streams support seeking and with <em>afl-fuzz</em> the situation is more tricky. If you execute the program normally and read from <code class="highlighter-rouge">sys.stdin</code>, by default the standard input does not support seeking. But when you run it through <em>afl-fuzz</em>, the standard input is in reality a file descriptor that is backed up by a file on a file system. And this file supports seeking. So you need some extra code to detect if the standard input supports seeking or not:</p><div id="instrumentation-persistent-rewind" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Python 3:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="nb">buffer</span>
<span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
    <span class="c"># There is no buffer attribute in Python 2:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Figure out if the standard input supports seeking or not:</span>
    <span class="n">stdin_compat</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">rewind</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span> <span class="n">stream</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c"># In Python 2 and 3 seek failure exception differs:</span>
<span class="k">except</span> <span class="p">(</span><span class="nb">IOError</span><span class="p">,</span> <span class="nb">OSError</span><span class="p">):</span>
    <span class="c"># Do nothing if we can not seek the stream:</span>
    <span class="k">def</span> <span class="nf">rewind</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span> <span class="k">pass</span>

<span class="k">while</span> <span class="n">afl</span><span class="o">.</span><span class="n">loop</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
    <span class="n">rewind</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>The effect of adding standard input rewinding more than doubles the fuzzing overhead for the persistent mode on the Debian GNU/Linux system that I have used to do these benchmarks. On OS X the effect is less than 10 % overhead increase for Python 3 and is required for Python 2 to even work with <em>afl-fuzz</em> on OS X.</p><h3 id="benchmarking-different-afl-fuzz-modes">Benchmarking different afl-fuzz modes</h3><p>I wanted to measure how these different <em>afl-fuzz</em> modes behave with Python. So I created a small fuzz target whose main algorithm does some conditional computation based on the input data and prints out the result:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fuzz_one</span><span class="p">(</span><span class="n">stdin</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">stdin</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="c"># This only includes lowercase ASCII letters:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="mi">5</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="mi">3</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="mi">2</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
</code></pre></div></div><p>This is just to exercise the fuzzer a little bit more than a trivial function that does nothing would do. I also created an equivalent fuzz target in C++ to give numbers to compare what kind of an overhead different fuzzing modes incur for both Python and native applications. The approximate results are summarized in table <a href="#table-benchmarks">1</a>. The actual scripts used to generate this data are available from following links: <a href="measure-times.sh">measure-times.sh</a>, <a href="target-simple.template.py">target-simple.template.py</a>, and <a href="target-simple.cpp">target-simple.cpp</a>.</p><div class="text-center"> <figure class="inline-figure" id="table-benchmarks"><table style="margin:0 auto"><thead><tr><th style="text-align:left"> </th><th style="text-align:right">Python 2</th><th style="text-align:right">Python 3</th><th style="text-align:right">Native</th></tr></thead><tbody><tr><td style="text-align:left"><a href="#afl-dumb-mode">dumb mode</a></td><td style="text-align:right">110/s</td><td style="text-align:right">47/s</td><td style="text-align:right">1200/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-pre-init">pre-init</a></td><td style="text-align:right">130/s</td><td style="text-align:right">46/s</td><td style="text-align:right">5800/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-deferred">deferred</a></td><td style="text-align:right">560/s</td><td style="text-align:right">260/s</td><td style="text-align:right">6800/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-os-exit-stdin">quick exit</a></td><td style="text-align:right">2700/s</td><td style="text-align:right">2100/s</td><td style="text-align:right">8700/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-persistent-rewind">rewinding persistent mode</a></td><td style="text-align:right">5800/s</td><td style="text-align:right">5900/s</td><td style="text-align:right">-</td></tr><tr><td style="text-align:left"><a href="#instrumentation-persistent">persistent mode</a></td><td style="text-align:right">17000/s</td><td style="text-align:right">15000/s</td><td style="text-align:right">44000/s</td></tr></tbody></table><figcaption class="text-center">Table 1: afl-fuzz benchmarks for various fuzzing modes for Python 2, Python 3, and for C++ versions of the example fuzz target.</figcaption> </figure></div><p>What these results show, it is possible to make fuzzable program in Python in such way that the fuzzing start-up overhead is only three to four times larger than for a native one with <em>afl-fuzz</em>. This is an excellent result considering that generally algorithms implemented in Python can be considered 10-100 times slower than ones implemented in C family languages. But if you want to use Python for performance critical tasks, you are anyways using <a href="http://cython.org/">Cython</a> or <a href="https://docs.python.org/2/extending/extending.html">write performance critical parts in C</a>.</p><p>There is a clear performance difference between Python 2.7.14 and Python 3.6.4 especially when all start-up and exit optimization tricks are not in use. This difference is also visible in Python start-up benchmarks at <a href="https://speed.python.org/">speed.python.org</a>. This difference gets smaller when the persistent mode is used as Python executable is not shut down immediately after processing one input. What can also help Python 3 in the persistent fuzzing mode is the fact that the tracing function that python-afl sets with <a href="https://docs.python.org/2/library/sys.html#sys.settrace">sys.settrace()</a> is called only half as often with Python 3 is it is called with Python 2 for this fuzz target.</p><h2 id="more-speed-for-repeated-python-executions">More speed for repeated Python executions</h2><p>Python enables imports and other type of code loading at any phase of the program execution. This makes it quite possible that program has not fully loaded before it is executed for the first time. This is usually used as a configuration mechanism to configure the program based on the runtime environment and other type of configuration. It also provides the possibility to write plugins, similarly to what <a href="https://en.wikipedia.org/wiki/Dynamic_loading">dynamically loaded libraries</a> provide.</p><p>You can see from table <a href="#table-benchmarks">1</a> how the fuzzing overhead decreases a lot when the fuzzing start point moved after <code class="highlighter-rouge">import</code> statements for this simple example program. So when I was fuzzing an old version of <a href="https://pypi.python.org/pypi/flake8">flake8</a>, I tried to see if it had any hidden configuration statements that would execute and cache their results for repeated calls. And it did!</p><p>Initially I used following type of fuzzing wrapper for flake8:</p><pre><code class="language-python2">import afl, sys, flake8.run
afl.init()
flake8.run.check_code(sys.stdin.read())
</code></pre><p>It is basically a simple wrapper that imports all what it needs and then fuzzes what is fed from the standard input to the program. But the performance of this was horrible, around 15 executions/second. So I tried to see what happens when I change the code a little bit by calling the <code class="highlighter-rouge">flake8.run.check_code()</code> function with an empty string before setting the fuzzing starting point:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">sys</span><span class="p">,</span> <span class="n">flake8</span><span class="o">.</span><span class="n">run</span>
<span class="c"># Make sure that the hidden runtime configuration is executed:</span>
<span class="n">flake8</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">check_code</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">flake8</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">check_code</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</code></pre></div></div><p>This doubled the execution speed to around 30 executions/second. It is still quite slow for the small inputs that <em>afl-fuzz</em> initially creates, but an improvement nonetheless. I looked at what flake8 does when it is executed and a following line popped up:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pkg_resources</span> <span class="kn">import</span> <span class="n">iter_entry_points</span>
</code></pre></div></div><p>There basically is a hidden <code class="highlighter-rouge">import</code> statement in the execution path whose result is cached after the first time it is encountered. Also this <code class="highlighter-rouge">pkg_resources.iter_entry_points()</code> function is used to <a href="http://setuptools.readthedocs.io/en/latest/pkg_resources.html#entry-points">configure the program at runtime</a> and that also adds some extra overhead to the process.</p><p>Flake8 also by default tries to execute checks in parallel with <a href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing module</a>. This might be a good idea when you have multiple files to verify at once, but during fuzzing it just adds unneeded overhead. Also the fact that it starts a new process makes the fuzzer lose all information about what is happening in the subprocess. Fortunately in flake8 it was possible to override the detected multiprocessing support by just setting one variable into <code class="language-python highlighter-rouge"><span class="bp">False</span></code> and then flake8 will act as there is no multiprocessing support. This increased the average fuzzing speed of flake8 by threefold.</p><p>The final speedup with flake8 came when looking at how flake8 is constructed. It is basically a wrapper around <a href="https://pypi.python.org/pypi/mccabe/">mccabe</a>, <a href="https://pypi.python.org/pypi/pycodestyle/">pycodestyle</a>, and <a href="https://pypi.python.org/pypi/pyflakes/">pyflakes</a> packages. So rather than fuzz flake8, it is much more productive to create a fuzz target for each one of those packages individually. I did this for pycodestyle and ended up finally executing it with around 420 executions/second for trivial data and around 200 executions/second for more realistic. So basic recommendations on how to fuzz native programs also apply for Python.</p><h2 id="monkey-patching-around-fuzzing-barriers">Monkey patching around fuzzing barriers</h2><p>As american fuzzy lop does not know almost anything about the input, it can encounter various impediments (see section 13 from <a href="http://lcamtuf.coredump.cx/afl/README.txt">afl’s README.txt</a>) when the file format includes any values that depend on the previously encountered data. This is especially problematic with checksums and is also an issue with other mutation based fuzzers. To work around this the C world, you can generally use <a href="https://llvm.org/docs/LibFuzzer.html#fuzzer-friendly-build-mode">C preprocessor to turn off checksum verification</a> when such thing is encountered. This also applies for all other types of barriers that might skew fuzzing results, like random number usage.</p><p>Unfortunately Python does not have preprocessor support by default, so this type of conditional compiling is out of the question. Fortunately Python provides the possibility to do <a href="https://en.wikipedia.org/wiki/Monkey_patch">monkey patching</a> where you can replace functions or methods at runtime. So to make a library more fuzzer friendly, you can monkey patch all functions related to data verification to always return <code class="highlighter-rouge">True</code>, or return some constant value when checksums are considered.</p><p>I used this approach to fuzz <a href="https://pypi.python.org/pypi/python-evtx/0.6.1">python-evxt 0.6.1</a> library. Python-evxt is a library to parse Windows event log files and is one of the first hits when you search <a href="https://pypi.python.org/">Python Package Index</a> with “pure python parser” keyword. The file format includes <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check#CRC-32_algorithm">CRC32</a> checksum that will prevent the fuzzer from being able to meaningfully modify the input file, as almost all modifications will create an incorrect checksum in the file.</p><p>To monkey patch around this issue, I searched the source code for all functions that potentially have anything to do with checksum generation and made them always to return a constant value:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">Evtx.Evtx</span>

<span class="n">checksum_patches</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"calculate_header_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"header_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"calculate_data_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"data_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">FileHeader</span><span class="p">,</span> <span class="s">"checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">FileHeader</span><span class="p">,</span> <span class="s">"calculate_checksum"</span><span class="p">),</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">class_obj</span><span class="p">,</span> <span class="n">method_name</span> <span class="ow">in</span> <span class="n">checksum_patches</span><span class="p">:</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">class_obj</span><span class="p">,</span> <span class="n">method_name</span><span class="p">,</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>The <code class="language-python highlighter-rouge"><span class="n">checksum_patches</span></code> variable holds all the functions that you need to overwrite to ignore checksums. You can use <code class="highlighter-rouge">setattr()</code> to overwrite these methods on class level with an anonymous function <code class="language-python highlighter-rouge"><span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">:</span> <span class="mi">0</span></code> that always returns <code class="highlighter-rouge">0</code> and takes any arguments. Taking any number of arguments in any fashion is enabled with <code class="highlighter-rouge">*args</code> and <code class="highlighter-rouge">**kw</code> and this syntax is explained in <a href="https://docs.python.org/2/tutorial/controlflow.html#keyword-arguments">keyword arguments</a> section on Python’s control flow tools manual.</p><h2 id="takeaways">Takeaways</h2><p>I was impressed on how low fuzzing overhead Python programs can have when compared to C family languages. When looking at how python-afl is implemented, it becomes quite clear that the deferred mode of <em>afl-fuzz</em> has a great part in this where the whole Python environment and program initialization is skipped between different fuzzing runs.</p><p>Making a Python module fuzzable was also more easy than in C family languages. Although american fuzzy lop is already the easiest fuzzing engine to get started with, the fact that it uses clang to do the more advanced tricks often gives headaches when trying to get software to compile. The fact that I did not have to use any modified Python interpreter to get started but only had to <code class="highlighter-rouge">import afl</code> module made me to realize how many steps I skipped that I normally have to do when using american fuzzy lop on new systems.</p><p>Thanks to Python’s dynamic execution and monkey patching capabilities I could also try out fuzz target creation with external libraries without having to actually modify the original code. Especially selecting some specific functions to fuzz and overriding checksum generation would generally require nasty software patches with C family languages. Especially if there is <code class="highlighter-rouge">main()</code> function to override.</p><p>It was also nice to realize that the <code class="language-python highlighter-rouge"><span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> equivalent in standard C library function call <code class="language-c highlighter-rouge"><span class="n">_Exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> could help make light native fuzz targets even faster. The process cleanup in this relatively trivial C++ program adds almost 30% overhead for repeated program execution. Although it will likely break any <a href="https://github.com/google/sanitizers">sanitizer</a> that does any verification work during the exit, like searching for dynamically allocated memory that was not freed.</p></div></article><div id="disqus_thread"></div> <script>var disqus_config=function(){this.page.url="https://barro.github.io/2018/01/taking-a-look-at-python-afl/",this.page.identifier="/2018/01/taking-a-look-at-python-afl"};!function(){var t=document,a=t.createElement("script");a.src="//barro.disqus.com/embed.js",a.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(a)}()</script></div></div><footer class="site-footer"><div class="wrapper"><h2 class="footer-heading">Jussi Judin's weblog</h2><div class="footer-col-wrapper"><div class="footer-col footer-col-1"><ul class="contact-list"><li>Jussi Judin</li><li>jju<span>din</span>+github <span>AT</span> iki DOT <span>f</span>i</li></ul></div><div class="footer-col footer-col-2"><ul class="social-media-list"><li> <a href="https://github.com/barro" title="Barro">GitHub</a></li><li> <a href="https://bitbucket.org/barro" title="barro">Bitbucket</a></li><li> <a href="https://facebook.com/b4rr0" title="B4rr0">Facebook</a></li><li> <a href="https://twitter.com/B4rr0" title="@B4rr0">Twitter</a></li><li> <a href="https://plus.google.com/+JussiJudin-jj/" title="+JussiJudin-jj">Google+</a></li></ul></div><div class="footer-col footer-col-3"><p>Programming related topics. Maybe even some original content!</p></div></div></div></footer><script>!function(e,a,t,n,c,o,s){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,o=a.createElement(t),s=a.getElementsByTagName(t)[0],o.async=1,o.src=n,s.parentNode.insertBefore(o,s)}(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","UA-71880517-1","auto"),ga("send","pageview")</script></body></html>