<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>Jussi Judin's weblog</title><meta name="description" content="Programming related topics. Maybe even some original content!
"/><link rel="stylesheet" href="/css/main.css"/><link rel="canonical" href="https://barro.github.io/"/><link rel="alternate" type="application/rss+xml" title="Jussi Judin's weblog" href="https://feeds.feedburner.com/jussijudin"/><link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon-180x180.png"/><link rel="icon" type="image/png" href="/icons/favicon-32x32.png" sizes="32x32"/><link rel="icon" type="image/png" href="/icons/android-chrome-192x192.png" sizes="192x192"/><link rel="icon" type="image/png" href="/icons/favicon-96x96.png" sizes="96x96"/><link rel="icon" type="image/png" href="/icons/favicon-16x16.png" sizes="16x16"/><link rel="manifest" href="/icons/manifest.json"/><link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#00a300"/><meta name="msapplication-TileImage" content="/icons/mstile-144x144.png"/><meta name="theme-color" content="#ffffff"/><meta content="928229747232422" property="fb:app_id"/><meta content="Jussi Judin's weblog" property="og:site_name"/><meta content="Jussi Judin's weblog" property="og:title"/><meta content="website" property="og:type"/><meta content="Programming related topics. Maybe even some original content!
" property="og:description"/><meta content="https://barro.github.io/" property="og:url"/><meta property="og:image" content="https://barro.github.io/icons/parruki-440.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="@b4rr0"/><meta name="twitter:creator" content="@b4rr0"/><meta name="twitter:title" content="Jussi Judin's weblog"/><meta name="twitter:url" content="https://barro.github.io/"/><meta name="twitter:description" content="Programming related topics. Maybe even some original content!
"/><meta name="twitter:image:src" content="https://barro.github.io/icons/parruki-440.png"/></head><body><header class="site-header"><div class="wrapper"><a class="site-title" href="/">Jussi Judin's weblog</a><nav class="site-nav"> <a href="#" class="menu-icon"> <svg viewBox="0 0 18 15"> <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/> <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/> <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/> </svg> </a><div class="trigger"> <a class="page-link" href="/archive/">Archive</a> <a class="page-link" href="/author/">Author</a> <a class="page-link" href="https://feeds.feedburner.com/jussijudin">RSS</a></div> </nav></div></header><div class="page-content"><div class="wrapper"><div class="home"><h1 class="page-heading">Articles</h1><ul class="post-list"><li> <span class="post-meta">Sunday, Jun 10, 2018 • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Jussi Judin</span></span></span><h2> <a class="post-link" href="/2018/06/afl-fuzz-on-different-file-systems/">afl-fuzz on different file systems</a></h2><p>One day I was fuzzing around with <a href="http://lcamtuf.coredump.cx/afl/">american fuzzy lop</a> and accidentally pointed the output directory for fuzzer findings to point onto a file system on a physical disk instead of the usual shared memory file system. I noticed my mistake and changed the output directory to the usual place. Consequently there was a clear difference on how many fuzzing iterations/second <code class="highlighter-rouge">afl-fuzz</code> program could do. This then lead into this comparison of different file systems and fuzzing modes on them with the workload that <code class="highlighter-rouge">afl-fuzz</code> has.</p><h2 id="hardware-and-software-background">Hardware and software background</h2><p>Fuzzing is a computationally intensive way to find bugs in programs, usually fully exercising the machine CPU. This and writing data to the disk can have adverse effects on the hardware even if we are working with software. Some risks are listed in the common-sense risks section at <a href="http://lcamtuf.coredump.cx/afl/README.txt">american fuzzy lop’s README.txt</a> file that is a good read about the subject. In this article I’m mainly interested in what happens when you happen to point the output of <code class="highlighter-rouge">afl-fuzz</code> to a device with a specific file system.</p><h3 id="afl-fuzz-as-part-of-american-fuzzy-lop">afl-fuzz as part of american fuzzy lop</h3><p>American fuzzy lop is a successful generic purpose <a href="https://en.wikipedia.org/wiki/Fuzzing">fuzzer</a> that finds bugs for you while you sleep. <code class="highlighter-rouge">afl-fuzz</code> is the executable program that does the hard work of generating new data, repeatedly running the target program (fuzz target), and analyzing the results that come up in these fuzz target executions. It has handcrafted heuristics and fuzzing strategies that in practice provide quite successful results without the need for tuning.</p><div class="text-center"> <figure class="inline-figure" id="afl-fuzz-forkserver"><a href="https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-2900.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-736.webp 736w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-920.webp 920w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-1104.webp 1104w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-1472.webp 1472w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-2208.webp 2208w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-2900.webp 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/> <source type="image/png" srcset="https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-736.png 736w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-920.png 920w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-1104.png 1104w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-1472.png 1472w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-2208.png 2208w,     https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/afl-forkserver-visualization-2900.png 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/><img src="https://barro.github.io/2018/06/afl-fuzz-on-different-file-systems/.png Interworkings of afl-fuzz, the fork server, and the fuzz target.""  alt="Interworkings of afl-fuzz, the fork server, and the fuzz target." width="736" height="355" class="figure-image" title="Interworkings of afl-fuzz, the fork server, and the fuzz target."/></picture> </a><figcaption class="text-center"> Figure 1: Interworkings of afl-fuzz, the fork server, and the fuzz target. </figcaption> </figure></div><p><a href="#afl-fuzz-forkserver">Figure 1</a> roughly visualizes the different parts that are part of a fuzzing session when using <code class="highlighter-rouge">afl-fuzz</code>. It spawns the program that we try to fuzz. This program then creates a <a href="https://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html">fork server</a> that is responsible for communicating with the main <code class="highlighter-rouge">afl-fuzz</code> executable over <a href="http://man7.org/linux/man-pages/man2/pipe.2.html">pipes</a> and spawning new fuzz target instances with <a href="http://man7.org/linux/man-pages/man2/fork.2.html"><code class="highlighter-rouge">fork()</code></a> call. The fork server actually a small shim that is part of the fuzz target. Also the new program instance that <code class="highlighter-rouge">fork()</code> call spawns still technically holds a reference to the fork server, but those parts are just active at different times, visualized as gray in the figure. If the fuzz target is in <a href="https://lcamtuf.blogspot.com/2015/06/new-in-afl-persistent-mode.html">persistent mode</a>, it doesn’t get restarted for every new input.</p><p>Data is passed to the fuzz target either over standard input or over a newly created file that the fuzz target reads. Then the fuzz target executes itself by writing an execution trace to a <a href="http://man7.org/linux/man-pages/man7/shm_overview.7.html">shared memory</a> and finishes running. <code class="highlighter-rouge">afl-fuzz</code> then reads the trace left by the fuzz target from the shared memory and creates a new input by mutating old ones. What to mutate is controlled by the new and historical information that the instrumentation data from the fuzz target provides.</p><h3 id="solid-state-drives">Solid state drives</h3><p><a href="https://en.wikipedia.org/wiki/Solid-state_drive">Solid state drives</a> are nowadays the most common physical storage medium in generic and special purpose computers. They are fast and relatively decently priced for the storage needs of a regular software developer. The decently priced solid state drives come with a price of somewhat limited write endurance due to the properties of the physical world and manufacturing compromises.</p><p>Currently (early 2018) the write endurance of a solid state drive promises to be around half in terabytes than what the drive capacity is in gigabytes on consumer level drives using (<a href="https://en.wikipedia.org/wiki/Multi-level_cell">TLC NAND</a>). This means that 200-250 gigabyte SSD has a write endurance around 100 terabytes. In practice, the write endurance will likely be more at least on <a href="https://techreport.com/review/27909/the-ssd-endurance-experiment-theyre-all-dead">a test from 2013-2015</a>.</p><p>Such write endurance does not really pose any limitations in the usual consumer level and professional workloads. But when it comes to fuzzing, it’s not the most usual workload. The whole idea of a fuzzer is to generate new data all the time, make the program execute it, and then either discard or save it depending of the program behavior is interesting or not. So we can expect that a fuzzer will generate quite a lot of data while it’s running.</p><p>Quick back-of-the-envelope calculation when assuming 10 parallel fuzzers running 1000 executions/second with 1000 byte input/execution on average would result in over 20 terabytes of data generated every month. If all this is directly written to a drive, then we can expect to have around 5 months until we reach the promised write endurance limits of a typical solid state drive at the time of this writing. There is caching that works to prolong this, but then there are all the invisible file system data structures, minimum file system block sizes, and <a href="https://en.wikipedia.org/wiki/Write_amplification">write amplification</a> then fight against these savings.</p><h3 id="two-data-passing-modes-of-afl-fuzz">Two data passing modes of afl-fuzz</h3><p><code class="highlighter-rouge">afl-fuzz</code> program has two ways to pass the new input to the fuzz target: passing the data over the standard input and creating a new file with the new data and having the fuzz target to read the data from the just created file file.</p><p>The most compact <code class="highlighter-rouge">afl-fuzz</code> command only includes the information for initial inputs, output directory and the command to execute the fuzz target without any special arguments:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>afl-fuzz <span class="nt">-i</span> <span class="k">in</span>/ <span class="nt">-o</span> out/ <span class="nt">--</span> fuzz-target
</code></pre></div></div><p>The fuzz target gets the input data from its standard input file descriptor so it does not need to explicitly open any files. Technically the standard input of the child process is backed by a file that is always modified by the <code class="highlighter-rouge">afl-fuzz</code> process when new input it generated. This file is also <code class="highlighter-rouge">.cur_input</code> file at the fuzzer instance directory. The exact details of how this works are explained later.</p><p>The more explicit input file path information including commands look like this:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># "@@" indicates the name of the file that the program gets with new</span>
<span class="c"># fuzz data. "-f" can be used to hard code the input file location</span>
<span class="c"># that then can be passed to the fuzz target or not.</span>
<span class="nv">$ </span>afl-fuzz <span class="nt">-i</span> <span class="k">in</span>/ <span class="nt">-o</span> out/ <span class="nt">--</span> fuzz-target @@
<span class="nv">$ </span>afl-fuzz <span class="nt">-i</span> <span class="k">in</span>/ <span class="nt">-o</span> out/ <span class="nt">-f</span> target.file <span class="nt">--</span> fuzz-target @@
<span class="nv">$ </span>afl-fuzz <span class="nt">-i</span> <span class="k">in</span>/ <span class="nt">-o</span> out/ <span class="nt">-f</span> target.file <span class="nt">--</span> fuzz-target
</code></pre></div></div><p>In the first command there is no explicit path to the input file specified, so the target program will get the path as the first argument, indicated by <code class="highlighter-rouge">@@</code>. The actual file is located at the fuzzer instance output directory (here it’s <code class="highlighter-rouge">out/</code>) as <code class="highlighter-rouge">.cur_input</code> file. Second two forms with <code class="highlighter-rouge">-f target.file</code> switch make it possible to define the location of the input file so that it can reside outside the output directory.</p><h4 id="details-of-input-data-writing">Details of input data writing</h4><p>Now that we know that <code class="highlighter-rouge">afl-fuzz</code> provides two different ways for the data to end in the program, then let’s look at the extracted details of <a href="https://github.com/mirrorer/afl/blob/2fb5a3482ec27b593c57258baae7089ebdc89043/afl-fuzz.c#L2468" title="afl 2.52b">write_to_testcase() function</a> to see how this data is passed to the child process.</p><p id="data-passing-stdin">When <code class="highlighter-rouge">afl-fuzz</code> writes data into the standard input stream of the fuzz target, the main parts of the code look like this in both <code class="highlighter-rouge">afl-fuzz</code> and fuzz target side:</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// afl-fuzz part:
</span><span class="p">{</span>
    <span class="c1">// Make sure that reads done by fuzz target do not affect
</span>    <span class="c1">// new testcase writes:
</span>    <span class="n">lseek</span><span class="p">(</span><span class="n">testcase_fd</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">SEEK_SET</span><span class="p">);</span>
    <span class="c1">// Write new testcase data to the file:
</span>    <span class="n">write</span><span class="p">(</span><span class="n">testcase_fd</span><span class="p">,</span> <span class="n">testcase_data</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="c1">// Make sure that old data in testcase file does not leak
</span>    <span class="c1">// into the new fuzzing iteration:
</span>    <span class="n">ftruncate</span><span class="p">(</span><span class="n">testcase_fd</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="c1">// Make read() act as it would read a fresh standard input
</span>    <span class="c1">// instance:
</span>    <span class="n">lseek</span><span class="p">(</span><span class="n">testcase_fd</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">SEEK_SET</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// Fuzz target part:
</span><span class="p">{</span>
    <span class="c1">// stdin file descriptor inside fuzz target is actually
</span>    <span class="c1">// identical to testcase_fd thanks to dup2(). So we just
</span>    <span class="c1">// read whatever happens to be there:
</span>    <span class="kt">ssize_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">testcase_fd</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
    <span class="c1">// Do some actual fuzzing:
</span>    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div><p>What happens in here that first the position in the file is changed to the beginning. A new data is written over the old one. The file length is changed to correspond to the new data length. The position is set to the beginning of the file again. Then the fuzz target reads from this file descriptor and runs the just written data through the actual program logic.</p><p id="data-passing-file">When passing data to the program through a named file following types of operations happen:</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// afl-fuzz part:
</span><span class="p">{</span>
    <span class="c1">// Remove the old output file.
</span>    <span class="n">unlink</span><span class="p">(</span><span class="n">out_file</span><span class="p">);</span>
    <span class="c1">// Create a new file with the same name.
</span>    <span class="kt">int</span> <span class="n">out_fd</span> <span class="o">=</span> <span class="n">open</span><span class="p">(</span><span class="n">out_file</span><span class="p">,</span> <span class="n">O_WRONLY</span> <span class="o">|</span> <span class="n">O_CREAT</span> <span class="o">|</span> <span class="n">O_EXCL</span><span class="p">,</span> <span class="mo">0600</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">out_fd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="n">abort</span><span class="p">();</span> <span class="p">}</span>
    <span class="c1">// Write the test data into the created file.
</span>    <span class="n">write</span><span class="p">(</span><span class="n">out_fd</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="c1">// Close the created file so that the data is available to other
</span>    <span class="c1">// processes.
</span>    <span class="n">close</span><span class="p">(</span><span class="n">out_fd</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// Fuzz target part:
</span><span class="p">{</span>
    <span class="c1">// Open the file created by afl-fuzz.
</span>    <span class="kt">int</span> <span class="n">in_fd</span> <span class="o">=</span> <span class="n">open</span><span class="p">(</span><span class="n">out_file</span><span class="p">,</span> <span class="n">O_RDONLY</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">in_fd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="n">abort</span><span class="p">();</span> <span class="p">}</span>
    <span class="c1">// Read enough data from the opened file descriptor for fuzzing.
</span>    <span class="kt">ssize_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">in_fd</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
    <span class="c1">// Close the opened file descriptor so that we don't leak
</span>    <span class="c1">// resources.
</span>    <span class="n">close</span><span class="p">(</span><span class="n">in_fd</span><span class="p">);</span>
    <span class="c1">// Do some actual fuzzing:
</span>    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div><p>Basically old input file is removed and a new file is created, data is written to it and it’s closed. Then the fuzz target opens the just created file, reads the data out of it and closes the opened file descriptor closes it, and runs the data through the actual program logic.</p><p>You can already see that there are more file system related functions used when the fuzz data file is recreated. Then these functions are also more heavy than the ones used in the standard input version. When you call <a href="http://man7.org/linux/man-pages/man2/unlink.2.html"><code class="highlighter-rouge">unlink()</code></a> and <a href="http://man7.org/linux/man-pages/man2/open.2.html"><code class="highlighter-rouge">open()</code></a>, Linux kernel needs to do <a href="https://github.com/torvalds/linux/blob/03f51d4efa2287cc628bb20b0c032036d2a9e66a/Documentation/filesystems/path-lookup.md">pathname lookup</a> to figure out what exact file objects are accessed. When you only have the file descriptor to manipulate in the standard input case, you avoid these pathname lookups and hopefully manipulate purely numeric data. Also when you open a new file, it has to actually create the corresponding <a href="https://en.wikipedia.org/wiki/Inode">inodes</a> and their data structures to the file system. This has a certain amount of overhead.</p><p>So looking at the called functions, it would feel like there is going to be a fuzzing overhead difference between these two input data creation approaches.</p><h2 id="benchmarking">Benchmarking</h2><p>Theoretical speculation is always nice, but the real hard data comes from the benchmarking. This section looks at the fuzzing overhead from both <code class="highlighter-rouge">afl-fuzz</code> perspective with low and high level filesystem access functions and from raw file system access perspective. Also the <a href="#data-writes">section about data writes</a> tries to find an answer to the question that how damaging fuzzing can actually be to a solid state drive with a relatively limited write endurance.</p><p>I did these benchmarks with several major general purpose file systems found from <a href="https://www.debian.org/">Debian</a> provided Linux kernels 4.14.13-1 and 4.15.11-1. These can show up as differences in numbers between tables, but numbers inside the same table are done with the same system. Also there is small variance between fuzzing sessions that I have tried to eliminate running the fuzzers for long enough that system maintenance and other short running tasks don’t have too big of an impact. But the relative mileage may vary between kernel versions, operating system libraries, and between the actual physical machines.</p><h3 id="executionssecond">Executions/second</h3><p>General purpose instrumentation guided fuzzers like american fuzzy lop and <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> get their power from the fact that they can repeatedly execute the fuzz target in quick succession. Speed is one factor, but also the program stability from one execution to another is a second one. Having stable program ensures that the issues that fuzzing finds can be easily replicated. This basically leads into a compromise of selecting the appropriate fuzzer and fuzz target execution strategy.</p><p>It can be that the program has a global state that needs program restart or other tricks between runs. For these types of situations the default forkserver mode in <code class="highlighter-rouge">afl-fuzz</code> is appropriate. On the other hand if everything can be functionally wrapped inside a function that does not leak its state outside, we can use the much faster persistent mode in <code class="highlighter-rouge">afl-fuzz</code>. From this it should be actually quite easy to port the fuzz target to libFuzzer.</p><p>In this case libFuzzer shows 735 k executions/second with the <a href="#the-example-fuzz-target">sample target</a> when the data is not passed between process boundaries. It is also possible to simulate in-memory file streams with <a href="http://man7.org/linux/man-pages/man3/fmemopen.3.html"><code class="highlighter-rouge">fmemopen()</code></a> function where libFuzzer achieved with this example program 550 k executions/second. This is 15-20 times lower fuzzing overhead than with <code class="highlighter-rouge">afl-fuzz</code>. But in this article we focus on american fuzzy lop’s persistent mode and leave the fuzzing engine selection for some other time.</p><p>A typical american fuzzy lop’s persistent mode fuzz target would generally have some generic configuration in the beginning and then the actual data dependent program execution would reside inside a <code class="highlighter-rouge">while (__AFL_LOOP(40000)) { ... }</code> loop. The number 40000 is just the number of iterations that the program does before it restarts again and can be lower or higher depending on how confident you are that the program does not badly misbehave.</p><p>Using the standard input with the persistent mode makes the data reading code look like following:</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generic_configuration</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span>
<span class="kt">int</span> <span class="n">input_fd</span> <span class="o">=</span> <span class="n">fileno</span><span class="p">(</span><span class="n">stdin</span><span class="p">);</span>
<span class="k">while</span> <span class="p">(</span><span class="n">__AFL_LOOP</span><span class="p">(</span><span class="mi">40000</span><span class="p">))</span> <span class="p">{</span>
    <span class="kt">ssize_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">input_fd</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">read_size</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="n">abort</span><span class="p">();</span> <span class="p">}</span>
    <span class="c1">// Do the actual fuzzing.
</span>    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div><p>Using named files with the persistent mode on the other hand requires opening a new file every iteration:</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generic_configuration</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span>
<span class="k">while</span> <span class="p">(</span><span class="n">__AFL_LOOP</span><span class="p">(</span><span class="mi">40000</span><span class="p">))</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">input_fd</span> <span class="o">=</span> <span class="n">open</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">O_RDONLY</span><span class="p">);</span>
    <span class="kt">ssize_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">input_fd</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">read_size</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="n">abort</span><span class="p">();</span> <span class="p">}</span>
    <span class="n">close</span><span class="p">(</span><span class="n">input_fd</span><span class="p">);</span>
    <span class="c1">// Do the actual fuzzing.
</span>    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div><h4 id="the-example-fuzz-target">The example fuzz target</h4><p>I directly used the code from my <a href="/2018/01/taking-a-look-at-python-afl/">Taking a look at python-afl</a> article and modified it to support the file and stdin reader variants. This code is available from <a href="target-simple.cpp">target-simple.cpp</a> for the prying eyes. Also the later on introduced C and C++ standard library variants are available as <a href="target-fread.cpp">target-fread.cpp</a> and <a href="target-ifstream.cpp">target-ifstream.cpp</a>.</p><h4 id="file-system-dependent-results">File system dependent results</h4><p>The benchmarking was done with a <a href="https://linux.die.net/man/8/losetup">loopback device</a> that fully resides in memory. Each of these file systems was created and mounted with their default options and the performance test was run for 2 minutes. Only a single instance of <code class="highlighter-rouge">afl-fuzz</code> was running. You can see from the <a href="#execs-per-second">table 1</a> the difference between the same workload on different file systems. The <a href="https://www.kernel.org/doc/gorman/html/understand/understand015.html">shared memory virtual file system</a> (tmpfs) was the most efficient in both of these cases.</p><div class="text-center"> <figure class="inline-figure" id="execs-per-second"><table style="margin:0 auto"><thead><tr><th style="text-align:left">execs/second</th><th style="text-align:right"><a href="#data-passing-stdin">stdin</a></th><th style="text-align:right"><a href="#data-passing-file">file</a></th></tr></thead><tbody><tr><td style="text-align:left">btrfs</td><td style="text-align:right">20.5 k</td><td style="text-align:right">14.6 k</td></tr><tr><td style="text-align:left">ext2</td><td style="text-align:right">31.6 k</td><td style="text-align:right">19.2 k</td></tr><tr><td style="text-align:left">ext3</td><td style="text-align:right">30.0 k</td><td style="text-align:right">18.4 k</td></tr><tr><td style="text-align:left">ext4</td><td style="text-align:right">28.0 k</td><td style="text-align:right">18.2 k</td></tr><tr><td style="text-align:left">JFS</td><td style="text-align:right">31.7 k</td><td style="text-align:right">17.1 k</td></tr><tr><td style="text-align:left">ReiserFS</td><td style="text-align:right">28.0 k</td><td style="text-align:right">14.5 k</td></tr><tr><td style="text-align:left">tmpfs</td><td style="text-align:right"><strong>34.6 k</strong></td><td style="text-align:right"><strong>25.5 k</strong></td></tr><tr><td style="text-align:left">XFS</td><td style="text-align:right">21.1 k</td><td style="text-align:right">16.8 k</td></tr></tbody></table><figcaption class="text-center">Table 1: Average number of fuzz target executions/second over 2 minute measuring period with different file systems.</figcaption> </figure></div><p>This result also shows an interesting history between ext2, ext3, and ext4 file systems. Their performance seems to decrease the newer the file system is, likely due to larger amount of data safety operations that the newer file systems do. There could be difference when parallel access to a file system is concerned.</p><h3 id="execution-speed-with-different-standard-libraries">Execution speed with different standard libraries</h3><p>I also wanted to see how the use of more portable file system calls in both C and C++ standard libraries affects the fuzzing speed. Standard libraries like <a href="https://www.gnu.org/software/libc/">glibc</a>, <a href="https://gcc.gnu.org/onlinedocs/libstdc++/">libstdc++</a>, and <a href="https://libcxx.llvm.org/">libc++</a> provide a portable file system interface across operating systems. They also provide a certain amount of buffering so that every small read does not result in a system call and suffer from context switch overhead. These higher level library functions also aim to be thread safe so that concurrent manipulation of the same file descriptor would be a little bit less surprising.</p><p>When doing fuzzing, we are usually just reading small amount of data once and then either close the input file or expect the <code class="highlighter-rouge">afl-fuzz</code> to <a href="#data-passing-stdin">reset the input stream for us</a>. Any buffering information must also be discarded and the stream position must be reset so that the input data for the fuzz target is the same what <code class="highlighter-rouge">afl-fuzz</code> expects it to be. If it’s not, it will show as a lower than 100 % stability value on <a href="http://lcamtuf.coredump.cx/afl/status_screen.txt">AFL status screen</a>.</p><p>Following is the C code used to benchmark how much overhead the standard C library functions bring into this. Standard input is put into unbuffered mode with <a href="http://man7.org/linux/man-pages/man3/setvbuf.3p.html"><code class="highlighter-rouge">setvbuf()</code></a> function call, so buffer manipulation should not have a meaningful amount of overhead.</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// C version for glibc benchmarking with standard file manipulation functions.
</span>
<span class="kt">FILE</span><span class="o">*</span> <span class="n">input_fd</span> <span class="o">=</span> <span class="n">stdin</span><span class="p">;</span>
<span class="n">setvbuf</span><span class="p">(</span><span class="n">input_fd</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">_IONBF</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="k">while</span> <span class="p">(</span><span class="n">__AFL_LOOP</span><span class="p">(</span><span class="mi">40000</span><span class="p">))</span> <span class="p">{</span>
    <span class="kt">size_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">fread</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">),</span> <span class="n">input_fd</span><span class="p">);</span>
    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// We get the fuzz data filename from argv[1].
</span><span class="k">while</span> <span class="p">(</span><span class="n">__AFL_LOOP</span><span class="p">(</span><span class="mi">40000</span><span class="p">))</span> <span class="p">{</span>
    <span class="kt">FILE</span><span class="o">*</span> <span class="n">input_fd</span> <span class="o">=</span> <span class="n">fopen</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"rb"</span><span class="p">);</span>
    <span class="kt">size_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">fread</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">),</span> <span class="n">input_fd</span><span class="p">);</span>
    <span class="n">fclose</span><span class="p">(</span><span class="n">input_fd</span><span class="p">);</span>
    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div><p>C++ streams don’t have a working unbuffered reads that would behave reliably. The closest equivalent to this is to call <a href="http://en.cppreference.com/w/cpp/io/basic_istream/seekg"><code class="highlighter-rouge">istream::seekg()</code></a> and after that <a href="http://en.cppreference.com/w/cpp/io/basic_ios/clear"><code class="highlighter-rouge">istream::clear()</code></a> function. This basically is theoretically equivalent to what <a href="http://man7.org/linux/man-pages/man3/rewind.3p.html"><code class="highlighter-rouge">rewind()</code></a> function does. Other solution of trying to set <a href="http://en.cppreference.com/w/cpp/io/basic_ios/rdbuf"><code class="highlighter-rouge">istream::rdbuf()</code></a> to a zero sized one had no real effect on increasing stability.</p><p>C++ code for these fuzzing benchmarks looks like following:</p><div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// C++ version for libstdc++ and libc++ benchmarking with the standard
// C++11 file manipulation functions.
</span>
<span class="k">auto</span> <span class="n">input_fd</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">cin</span><span class="p">;</span>
<span class="k">while</span> <span class="p">(</span><span class="n">__AFL_LOOP</span><span class="p">(</span><span class="mi">40000</span><span class="p">))</span> <span class="p">{</span>
    <span class="c1">// Resetting stream state is 2 function calls.
</span>    <span class="n">input_fd</span><span class="p">.</span><span class="n">seekg</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_fd</span><span class="p">.</span><span class="n">beg</span><span class="p">);</span>
    <span class="n">input_fd</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
    <span class="n">input_fd</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
    <span class="kt">size_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">input_fd</span><span class="p">.</span><span class="n">gcount</span><span class="p">();</span>
    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// We get the fuzz data filename from argv[1].
</span><span class="k">while</span> <span class="p">(</span><span class="n">__AFL_LOOP</span><span class="p">(</span><span class="mi">40000</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">ifstream</span> <span class="n">input_fd</span><span class="p">(</span>
        <span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">std</span><span class="o">::</span><span class="n">ifstream</span><span class="o">::</span><span class="n">in</span> <span class="o">|</span> <span class="n">std</span><span class="o">::</span><span class="n">ifstream</span><span class="o">::</span><span class="n">binary</span><span class="p">);</span>
    <span class="n">input_fd</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">));</span>
    <span class="kt">size_t</span> <span class="n">read_size</span> <span class="o">=</span> <span class="n">input_fd</span><span class="p">.</span><span class="n">gcount</span><span class="p">();</span>
    <span class="n">input_fd</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
    <span class="n">fuzz_one</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">read_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div><p>C++ code is a little bit more verbose than C code, as there are extra layers of abstraction that need to be removed so that <code class="highlighter-rouge">afl-fuzz</code> style data processing is possible. <a href="#libs-execs-per-second">Table 2</a> then shows what is the speed difference of these different implementations and standard libraries.</p><div class="text-center"> <figure class="inline-figure" id="libs-execs-per-second"><table style="margin:0 auto"><thead><tr><th style="text-align:left">execs/second</th><th style="text-align:right">syscalls</th><th style="text-align:right">glibc</th><th style="text-align:right">libstdc++</th><th style="text-align:right">libc++</th></tr></thead><tbody><tr><td style="text-align:left"><a href="#data-passing-stdin">stdin</a></td><td style="text-align:right">33.5 k</td><td style="text-align:right">32.4 k (98 %)</td><td style="text-align:right">31.2 k (93 %)</td><td style="text-align:right">30.7 k (92 %)*</td></tr><tr><td style="text-align:left"><a href="#data-passing-file">file</a></td><td style="text-align:right">24.2 k</td><td style="text-align:right">22.8 k (94 %)</td><td style="text-align:right">22.0 k (91 %)</td><td style="text-align:right">20.7 k (86 %)</td></tr></tbody></table><figcaption class="text-center">Table 2: Fuzz target executions/second over 2 minute period with different standard libraries on tmpfs.<div>* The stability of libc++ stdin session was not 100 %.</div></figcaption> </figure></div><p>We can see that the pure combination of <code class="highlighter-rouge">open()</code> and <code class="highlighter-rouge">read()</code> functions is the fastest one. Portable C standard library implementation comes quite close with the unbuffered standard input implementation, but everywhere else there is a clear performance loss.</p><p>Stability is an important measurement of how reliably fuzzing can continue. Unfortunately in this tests everything was not 100 % stable. The standard input reading and resetting for libc++ does not fully work as expected and leads into reading old data.</p><p>The conclusion here is that try to stay with the low level unbuffered file manipulation functions or as close to their equivalents. More portable higher level functions for file access may provide speed benefits through buffering for regular file access patterns, but in this case they just add extra layers that slow down the data passing from <code class="highlighter-rouge">afl-fuzz</code> to the fuzz target. Unless the fuzz target itself relies on using those higher level functions.</p><h3 id="data-writes">Data writes</h3><p>In the <a href="#hardware-and-software-background">background section</a> I described how it generally is a bad idea to write data to a physical disk, as modern solid state drives have a limited write durability. But one could think that the write caching done by Linux would prevent a situation from happening where data is constantly written to the disk if the lifetime of a file contents is really short.</p><p>The write caching towards block devices is handled by the <a href="https://en.wikipedia.org/wiki/Page_cache">page cache</a> in the kernel. But as different file systems may write every new file or file part into a new location, this cache is not necessarily as effective as it could be. Even if the writes happen to the same file with very little data.</p><p>In this section I let <code class="highlighter-rouge">afl-fuzz</code> to run for 30 minutes and looked at the kilobytes written by <a href="http://man7.org/linux/man-pages/man1/iostat.1.html"><code class="highlighter-rouge">iostat</code></a> to a block device that was a file in memory that was mounted on a <a href="https://linux.die.net/man/8/losetup">loopback device</a>. This way the device should have looked like a real block device without the risk of shortening the lifespan of any real hardware. Estimated monthly values for disk writes for various file systems can be seen from <a href="#data-writes-month-single">table 3</a> for a single <code class="highlighter-rouge">afl-fuzz</code> instance.</p><div class="text-center"> <figure class="inline-figure" id="data-writes-month-single"><table style="margin:0 auto"><thead><tr><th style="text-align:left">writes/month</th><th style="text-align:right"><a href="#data-passing-stdin">stdin</a></th><th style="text-align:right"><a href="#data-passing-file">file</a></th></tr></thead><tbody><tr><td style="text-align:left">btrfs</td><td style="text-align:right"><strong>3.052 TiB</strong></td><td style="text-align:right">0.020 TiB</td></tr><tr><td style="text-align:left">ext2</td><td style="text-align:right">0.004 TiB</td><td style="text-align:right">0.005 TiB</td></tr><tr><td style="text-align:left">ext3</td><td style="text-align:right">0.020 TiB</td><td style="text-align:right">0.028 TiB</td></tr><tr><td style="text-align:left">ext4</td><td style="text-align:right">0.035 TiB</td><td style="text-align:right">0.021 TiB</td></tr><tr><td style="text-align:left">JFS</td><td style="text-align:right"><strong>9.74 TiB</strong></td><td style="text-align:right"><strong>69.8 TiB</strong></td></tr><tr><td style="text-align:left">ReiserFS</td><td style="text-align:right">0.021 TiB</td><td style="text-align:right">0.024 TiB</td></tr><tr><td style="text-align:left">tmpfs</td><td style="text-align:right">-</td><td style="text-align:right">-</td></tr><tr><td style="text-align:left">XFS</td><td style="text-align:right"><strong>201 TiB</strong></td><td style="text-align:right">0.004 TiB</td></tr></tbody></table><figcaption class="text-center">Table 3: Estimated monthly data writes for a single fuzzer on different file systems.</figcaption> </figure></div><p>The numbers for the amount of data that would be written to the device is an extrapolation of the 30 minute run and show values are in terabytes (2<sup>40</sup> bytes). These numbers are for the persistent mode and for an extremely light algorithm. They still give some estimate on the amount of data writes to the disk even for algorithms that are 10-100 times slower. Nowadays a typical desktop computer can easily have 8-16 threads and the order of typically processed data per fuzzer iteration is closer to 1 kilobyte than to 128 bytes as in this case.</p><p>When looking at these numbers, btrfs, JFS, and XFS file systems are pretty dangerous ones to accidentally use, as the faster stdin mode where data is fed to always open file handle actually causes a meaningful amount of data to be written to a disk per month. Especially with XFS it’s 4 kilobytes of data written/fuzzing iteration. Taking into account that many solid state disk drives have write endurance only in hundreds of terabytes, accidentally running even one fuzzer for one month or more makes a significant dent in its lifetime for these file systems.</p><p>I also wanted to see what happens when you run multiple fuzzers in parallel on the same machine. The most trivial assumption for multiple fuzzers would be that the file system writes would increase about linearly with the number of fuzzers. The results on <a href="#data-writes-month-x4">table 4</a> show that this is indeed the case for most of the file systems, except for ext2. Fortunately ext2 is not the worst data writer of the measured file systems and you really need to go extra mile to use it nowadays, as newer ext3 and ext4 file systems have replaced it by default.</p><div class="text-center"> <figure class="inline-figure" id="data-writes-month-x4"><table style="margin:0 auto"><thead><tr><th style="text-align:left">writes/month</th><th style="text-align:right"><a href="#data-passing-stdin">stdin</a> x4</th><th style="text-align:right"><a href="#data-passing-file">file</a> x4</th></tr></thead><tbody><tr><td style="text-align:left">btrfs</td><td style="text-align:right"><strong>9.53 TiB</strong> (78 %)</td><td style="text-align:right">0.052 TiB (65 %)</td></tr><tr><td style="text-align:left">ext2</td><td style="text-align:right">0.072 TiB (<strong>450 %</strong>)</td><td style="text-align:right">0.120 TiB (<strong>600 %</strong>)</td></tr><tr><td style="text-align:left">ext3</td><td style="text-align:right">0.075 TiB (94 %)</td><td style="text-align:right">0.147 TiB (130 %)</td></tr><tr><td style="text-align:left">ext4</td><td style="text-align:right">0.090 TiB (64 %)</td><td style="text-align:right">0.088 TiB (100 %)</td></tr><tr><td style="text-align:left">JFS</td><td style="text-align:right"><strong>44.4 TiB</strong> (110 %)</td><td style="text-align:right"><strong>339 TiB</strong> (120 %)</td></tr><tr><td style="text-align:left">ReiserFS</td><td style="text-align:right">0.069 TiB (82 %)</td><td style="text-align:right">0.072 TiB (75 %)</td></tr><tr><td style="text-align:left">tmpfs</td><td style="text-align:right">-</td><td style="text-align:right">-</td></tr><tr><td style="text-align:left">XFS</td><td style="text-align:right"><strong>786 TiB</strong> (98 %)</td><td style="text-align:right">0.035 TiB (220 %)</td></tr></tbody></table><figcaption class="text-center">Table 4: Monthly data writes for a 4 parallel fuzzers on different file systems and the percentage to an extrapolated number based on one afl-fuzz instance.</figcaption> </figure></div><p>The worrying part here is that two quite actively and widely used file systems, btrfs and XFS, suffer greatly from the writes with the standard input data generation pattern. As this is the faster mode of fuzzing from executions/second perspective, it’s quite nasty if you put the output directory for fuzzer findings on such file system.</p><h3 id="theoretical-limits">Theoretical limits</h3><p>I also wanted to see what would be the theoretical limits for the type of file system access pattern that <code class="highlighter-rouge">afl-fuzz</code> does. This is quite a synthetic benchmark, as it does not involve any context switches between processes, <a href="http://man7.org/linux/man-pages/man7/signal.7.html">signal</a> delivery, <a href="http://man7.org/linux/man-pages/man7/shm_overview.7.html">shared memory</a> manipulation, <a href="http://man7.org/linux/man-pages/man2/dup.2.html">file descriptor duplication</a>, and other types of data processing that <code class="highlighter-rouge">afl-fuzz</code> does.</p><div class="text-center"> <figure class="inline-figure" id="theoretical-fs-benchmark"><table style="margin:0 auto"><thead><tr><th style="text-align:left">sequences/second</th><th style="text-align:right"><a href="#data-passing-stdin">stdin</a></th><th style="text-align:right"><a href="#data-passing-file">file</a></th></tr></thead><tbody><tr><td style="text-align:left">btrfs</td><td style="text-align:right">87.5 k</td><td style="text-align:right">40.7 k</td></tr><tr><td style="text-align:left">ext2</td><td style="text-align:right">446.1 k</td><td style="text-align:right">66.5 k</td></tr><tr><td style="text-align:left">ext3</td><td style="text-align:right">305.4 k</td><td style="text-align:right">60.3 k</td></tr><tr><td style="text-align:left">ext4</td><td style="text-align:right">211.5 k</td><td style="text-align:right">56.4 k</td></tr><tr><td style="text-align:left">JFS</td><td style="text-align:right"><strong>737.7 k</strong></td><td style="text-align:right">59.5 k</td></tr><tr><td style="text-align:left">ReiserFS</td><td style="text-align:right">594.1 k</td><td style="text-align:right">40.4 k</td></tr><tr><td style="text-align:left">tmpfs</td><td style="text-align:right">682.5 k</td><td style="text-align:right"><strong>138.0 k</strong></td></tr><tr><td style="text-align:left">XFS</td><td style="text-align:right">101.9 k</td><td style="text-align:right">48.5 k</td></tr></tbody></table><figcaption class="text-center">Table 5: Theoretical file system performance numbers with `afl-fuzz` like access pattern.</figcaption> </figure></div><p>The difference between file systems in <a href="#theoretical-fs-benchmark">table 5</a> is many times larger for standard input based data generation than for <code class="highlighter-rouge">afl-fuzz</code> (<a href="#execs-per-second">table 1</a>). When opening and closing files, the overhead is bigger and the difference between different file systems is also smaller.</p><p>If you also compare the overhead of pure file system accesses, it is higher than the overhead of <a href="#executionssecond">libFuzzer’s 735 k executions/second</a> basically for all cases. On top of this there is the overhead of everything else that happens inside <code class="highlighter-rouge">afl-fuzz</code> program.</p><h2 id="end-notes">End notes</h2><p>You should use tmpfs that fully resides in memory for your fuzzing data generation with <code class="highlighter-rouge">afl-fuzz</code>. Usually this is available on <code class="highlighter-rouge">/dev/shm/</code> or <code class="highlighter-rouge">/run/shm/</code> globally and on systemd based systems also available under <code class="highlighter-rouge">/run/user/$UID/</code>. It’s faster and less straining to the hardware than trusting that the Linux block layer does not too often write to the physical device. Especially if you happen to use btrfs or XFS file systems.</p><p>In the end, this is mostly Linux specific information and for example OS X based systems need <a href="https://gist.github.com/koshigoe/822455">specific tricks</a> to use memory based file systems. Same with FreeBSD where tmpfs based file system is not mounted by default.</p></li><li> <span class="post-meta">Sunday, Feb 4, 2018 • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Jussi Judin</span></span></span><h2> <a class="post-link" href="/2018/02/avatars-identicons-and-hash-visualization/">Avatars, identicons, and hash visualization</a></h2><p>Oftentimes we have a situation where we have a situation where we want an easy way to distinguish people of which we only know the name or a nickname. Probably the most common examples of these are distinguishing different people from each other on various discussion platforms, like chat rooms, forums, wikis, or issue tracking systems. These very often provide the possibility to use handles, often real names or nicknames, and profile images as an alternative. But as very often people don’t provide any profile image, many services use a programmatically generated images to give some uniqueness to default profile images.</p><p>In this article I’ll take a look at a few approaches to generate default profile images and other object identifiers. I also take a look at the process of creating some specific hash visualization algorithms that you may have encountered on the web. The general name for such programmatically generated images is hash visualization.</p><h2 id="use-cases-and-background">Use cases and background</h2><p>A starting point to visualize arbitrary data is often <a href="https://en.wikipedia.org/wiki/Hash_function">hashing</a>. Hashing in this context is to make a fixed length representation of an arbitrary value. This fixed length representation is just a big number that can be then used as a starting point for distinguishing different things from each other.</p><p>Hash visualization aims to generate a visual identifier for easy differentiation of different objects that takes an advantage of <a href="https://en.wikipedia.org/wiki/Pre-attentive_processing">preattentive processing</a> of human visual system. There are various categories that human visual system uses to do preattentive processing, like <span style="border-bottom:1px dashed" title="Ware, Colin. Information visualization: perception for design. Elsevier, 2012.">form, color, motion, and spatial position</span>. Different hash visualization schemes knowingly or unknowingly take advantage of these.</p><p>Simple methods use specific colors as a visualization method, but at the same time limit the values that can be preattentively distinguished to maybe around 10-20 (around 4 bits of information) per colored area. Using additional graphical elements provides a possibility to create more distinct unique elements that are easy to separate from each other. <span title="Kilian, Timo. Visualization of Hash-functions. June 2012."><a href="https://www.secuso.informatik.tu-darmstadt.de/fileadmin/user_upload/Group_SECUSO/Theses/BA/Visualization_of_Hash-functions.pdf">One thesis</a></span> tries hash visualization with 60 bits of data with varying success. So the amount of visualized data that can be easily distinguished from each other by graphical means is somewhere between 4 and 60 bits.</p><h2 id="avatars">Avatars</h2><p>Perhaps the most common way to distinguish different users of an Internet based service is to use an user name and an avatar image. Avatars often go with custom avatar images that users themselves upload to the service. In case the service itself does not want to host avatars, it can link to services like <a href="https://gravatar.com">Gravatar</a> that provides avatar hosting as a service. This way user can use the same avatar in multiple services just by providing their email address.</p><p>But what about a situation where the user has not uploaded or does not want to upload an avatar image to the service? There usually is a placeholder image that indicates that the user has not set their custom avatar.</p><p>There seem to be three major approaches to generate this placeholder image:</p><ol><li>A generic dummy placeholder image. These often come in a shape of a generic human profile.</li><li>An image from predefined collection of images. These are usually related to a theme that the site wants to present.</li><li>A partially or fully algorithmically generated image. These usually make it possible to get the most variety for placeholders with the least amount of work.</li></ol><p>Algorithmically generated images vary greatly and usually come in three varieties:</p><ol><li>Simple images that mainly use a color and a letter to distinguish users.</li><li>Images that consist of a set of a predefined parts and color variations.</li><li>More complex shapes usually created fully algorithmically.</li></ol><p>I have taken a closer look at different algorithmic avatar creation methods in form of <a href="#wordpress-identicon">WordPress identicon</a>, <a href="#github-identicon">GitHub identicon</a>, and <a href="#monsterid">MonsterID</a>. These provide an overview on how algorithmic avatar generation can work. There is also a chapter of using <a href="#character-on-a-colored-background">a character on a colored background</a> to give an example of a simple algorithmic method for default avatar generation.</p><p>I want to focus here on visualizing the few methods that I have encountered rather than having a all-encompassing overview of avatar generation. For that, there is <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">Avatar article on Wikipedia</a> that gives a better textual overview of these and many more methods than I could give.</p><h3 id="character-on-a-colored-background">Character on a colored background</h3><div class="text-center"> <figure class="inline-figure" id="colored-background-examples"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-2880.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-720.webp 720w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-960.webp 960w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-1152.webp 1152w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-1440.webp 1440w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-1920.webp 1920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-2880.webp 2880w" sizes="720px, 960px, 1152px, 1440px, 1920px, 2880px"/> <source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-720.png 720w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-960.png 960w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-1152.png 1152w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-1440.png 1440w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-1920.png 1920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-2880.png 2880w" sizes="720px, 960px, 1152px, 1440px, 1920px, 2880px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/colored-background-examples-720.png Avatar examples having a colored background with the first letter of an user name.""  alt="Avatar examples having a colored background with the first letter of an user name." width="720" height="120" class="figure-image" title="Avatar examples having a colored background with the first letter of an user name."/></picture> </a><figcaption> Figure 1: Avatar examples having a colored background with the first letter of an user name. </figcaption> </figure></div><p>Services like <a href="https://hangouts.google.com/">Google Hangouts</a>, <a href="https://telegram.org/">Telegram</a> and <a href="https://signal.org/">Signal</a>, and software with people collaboration functionality like <a href="https://www.atlassian.com/software/jira">Jira</a> generate a default avatar for an user by using the first letter of user’s name with a colored background. This is simple method where you need to select a font, a shape that you want to use to surround the letter, and size of the avatar. Some example avatars generated by this method are visible from <a href="#colored-background-examples">figure 1</a>.</p><h3 id="wordpress-identicon">WordPress identicon</h3><div class="text-center"> <figure class="inline-figure" id="identicon-examples"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-2880.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-720.webp 720w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-960.webp 960w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-1152.webp 1152w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-1440.webp 1440w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-1920.webp 1920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-2880.webp 2880w" sizes="720px, 960px, 1152px, 1440px, 1920px, 2880px"/> <source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-720.png 720w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-960.png 960w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-1152.png 1152w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-1440.png 1440w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-1920.png 1920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-2880.png 2880w" sizes="720px, 960px, 1152px, 1440px, 1920px, 2880px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-examples-720.png Example WordPress identicons.""  alt="Example WordPress identicons." width="720" height="120" class="figure-image" title="Example WordPress identicons."/></picture> </a><figcaption> Figure 2: Example WordPress identicons. </figcaption> </figure></div><p><a href="https://wordpress.org/plugins/wp-identicon/">WordPress identicon</a> has been a well known algorithmically generated avatar for quite long time on web forums. It has been used to distinguish between users based on their <a href="https://en.wikipedia.org/wiki/IP_address">IP addresses</a> and <a href="https://en.wikipedia.org/wiki/Email_address">email addresses</a>. Example WordPress identicons can be seen from <a href="#identicon-examples">figure 2</a> where you should be able to notice that there is some symmetry in these images.</p><div class="text-center"> <figure class="inline-figure" id="identicon-parts"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-2900.png"> <picture><source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-736.png 736w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-920.png 920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-1104.png 1104w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-1472.png 1472w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-2208.png 2208w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-2900.png 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-parts-736.png" alt="44 parts from which a WordPress identicon is generated." title="44 parts from which a WordPress identicon is generated." width="736" height="267" class="figure-image webfeedsFeaturedVisual"/></picture> </a><figcaption> Figure 3: 44 parts from which a WordPress identicon is generated. </figcaption> </figure></div><p>Looking at the code how these avatars are generated reveals 44 patterns, shown in <a href="#identicon-parts">figure 3</a> that the generators uses to generate these images. They are symmetrically placed around the center and rotated 90 degrees when they reach the next quadrant. This process is illustrated in <a href="#identicon-animated">figure 4</a> that shows how these parts are placed and rotated around the center. In case the requested identicon has an even number of parts, these parts will get duplicated. So 4x4 WordPress identicon will only have 3 distinct parts in it. This is the same number as for 3x3 WordPress identicon.</p><div class="text-center"> <figure class="inline-figure" id="identicon-animated"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-480.gif"> <picture><!--[if IE 9]><video style="display:none"><![endif]--><source type="image/apng" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-120.apng 120w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-150.apng 150w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-180.apng 180w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-240.apng 240w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-360.apng 360w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-480.apng 480w" sizes="120px, 150px, 180px, 240px, 360px, 480px"/> <source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-120.webp 120w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-150.webp 150w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-180.webp 180w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-240.webp 240w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-360.webp 360w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-480.webp 480w" sizes="120px, 150px, 180px, 240px, 360px, 480px"/> <source type="image/gif" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-120.gif 120w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-150.gif 150w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-180.gif 180w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-240.gif 240w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-360.gif 360w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-480.gif 480w" sizes="120px, 150px, 180px, 240px, 360px, 480px"/> <!--[if IE 9]></video><![endif]--><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/identicon-animated-120.gif 5x5 WordPress identicon generation animated." alt="5x5 WordPress identicon generation animated." width="120" height="120" title="5x5 WordPress identicon generation animated."/></picture> </a><figcaption> Figure 4: 5x5 WordPress identicon generation animated. </figcaption> </figure></div><h3 id="github-identicon">GitHub identicon</h3><div class="text-center"> <figure class="inline-figure" id="github-identicon-examples"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-2880.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-720.webp 720w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-1440.webp 1440w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-2160.webp 2160w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-2880.webp 2880w" sizes="720px, 1440px, 2160px, 2880px"/> <source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-720.png 720w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-1440.png 1440w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-2160.png 2160w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-2880.png 2880w" sizes="720px, 1440px, 2160px, 2880px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-examples-720.png Example GitHub style identicons.""  alt="Example GitHub style identicons." width="720" height="120" class="figure-image" title="Example GitHub style identicons."/></picture> </a><figcaption> Figure 5: Example GitHub style identicons. </figcaption> </figure></div><p><a href="https://github.com/">GitHub</a> is a great collaborative code repository sharing service where users can have identifying images. If user, however, does not have any profile image, <a href="https://github.com/blog/1586-identicons">GitHub will generate</a> an identicon that forms a 5x5 pixel sprite. <a href="#github-identicon-examples">Figure 5</a> examples how such identicons can look like. The exact algorithm that GitHub uses to generate these identicons is not public, so these example images just imitating the style of GitHub identicons.</p><div class="text-center"> <figure class="inline-figure" id="github-identicon-animated"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-480.gif"> <picture><!--[if IE 9]><video style="display:none"><![endif]--><source type="image/apng" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-120.apng 120w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-240.apng 240w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-360.apng 360w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-480.apng 480w" sizes="120px, 240px, 360px, 480px"/> <source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-120.webp 120w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-240.webp 240w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-360.webp 360w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-480.webp 480w" sizes="120px, 240px, 360px, 480px"/> <source type="image/gif" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-120.gif 120w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-240.gif 240w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-360.gif 360w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-480.gif 480w" sizes="120px, 240px, 360px, 480px"/> <!--[if IE 9]></video><![endif]--><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/github-identicon-animated-120.gif GitHub style identicon creation process animated. Visible pixels are horizontally mirrored." alt="GitHub style identicon creation process animated. Visible pixels are horizontally mirrored." width="120" height="120"/></picture> </a><figcaption> Figure 6: GitHub style identicon creation process animated. Visible pixels are horizontally mirrored. </figcaption> </figure></div><p><a href="#github-identicon-animated">Figure 6</a> shows the process of creating such identicon. Basically the given data is hashed and from that hash a specific color is selected as the value for a visible pixel. Then other part of the hash (15 bits) is used to form an image that is horizontally mirrored. I have used a modified <a href="https://github.com/chrisbranson/ruby_identicon">ruby_identicon</a> to generate these images and animations. This library also enables the generation of other sizes than 5x5 sprites.</p><h3 id="monsterid">MonsterID</h3><div class="text-center"> <figure class="inline-figure" id="monsterid-examples"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-examples-720.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-examples-720.webp 720w" sizes="720px"/> <source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-examples-720.png 720w" sizes="720px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-examples-720.png Example artistic MonsterIDs." alt="Example artistic MosterIDs." width="720" height="120" class="figure-image" title="Example artistic MosterIDs."/></picture> </a><figcaption> Figure 7: Example artistic MonsterIDs. </figcaption> </figure></div><p><a href="https://wordpress.org/plugins/wp-monsterid/">WordPress MonsterID</a> is a hash visualization method where hashes are converted to various types of monsters. It’s a one type of hash visualization method where lifelike creature is created from predefined body parts. WordPress MonsterID actually offers two types of monsters, the default ones and artistic ones. Here I’m showing some example artistic monsters in <a href="#monsterid-examples">figure 7</a> just because they look better than the default ones.</p><div class="text-center"> <figure class="inline-figure" id="monsterid-forming"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-forming-720.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-forming-720.webp 720w" sizes="720px"/> <source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-forming-720.png 720w" sizes="720px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-736.png Creating an artistic MonsterID image by selecting and colorizing an appropriate part from each category." alt="Creating an artistic MonsterID image by selecting and colorizing an appropriate part from each category." width="720" height="360" class="figure-image" title="Creating an artistic MonsterID image by selecting and colorizing an appropriate part from each category."/></picture> </a><figcaption> Figure 8: Creating an artistic MonsterID image by selecting and colorizing an appropriate part from each category. </figcaption> </figure></div><p><a href="#monsterid-forming">Figure 8</a> shows the MonsterID creation process. First there is a lightly colored background on top of which we start forming the monster. We select a body part in order of legs, hair, arms, body, eyes, and mouth. These parts are show in <a href="#monsterid-parts">figure 9</a>. Then assign a color to the selected part, unless it’s one of the special cases. Then just overlay it on top of the image formed from previous parts. There are special cases that what parts should have a predefined color or be left uncolored, but that does not change the general monster creation process.</p><div class="text-center"> <figure class="inline-figure" id="monsterid-parts"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-2400.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-736.webp 736w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-920.webp 920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-1104.webp 1104w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-1472.webp 1472w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-2208.webp 2400w" sizes="736px, 920px, 1104px, 1472px, 2400px"/> <source type="image/png" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-736.png 736w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-920.png 920w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-1104.png 1104w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-1472.png 1472w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-2900.png 2400w" sizes="736px, 920px, 1104px, 1472px, 2400px"/><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/monsterid-parts-736.png Parts from which a MonsterID is created divided into categories (hair, eyes, mouth, arms, body, and legs)." alt="Parts from which a MonsterID is created divided into categories (hair, eyes, mouth, arms, body, and legs)." width="736" height="221" class="figure-image" title="Parts from which a MonsterID is created divided into categories (hair, eyes, mouth, arms, body, and legs)."/></picture> </a><figcaption> Figure 9: Parts from which a MonsterID is created divided into categories (hair, eyes, mouth, arms, body, and legs). </figcaption> </figure></div><p>In addition to WordPress MonsterID plugin, <a href="https://en.gravatar.com/site/implement/images/">Gravatar</a> also supports old style MonsterIDs. These unfortunately do not as good as the artistic monsters in the WordPress MonsterID plugin and there is no option to select an alternative form for these avatars.</p><h2 id="openssh-visual-host-key">OpenSSH visual host key</h2><p>Hash visualization has also its place in cryptography. <a href="http://www.openssh.com/">OpenSSH</a> client has an option to display so called visual host keys.</p><p>When a SSH client connects to a remote server that it has not ever seen before, it needs to accept the public key of this server so that it can communicate with it securely. To prevent <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack">man-in-the-middle attacks</a>, user initiating the connection is supposed to verify that the host key indeed matches. An example message about host key verification request is shown in <a href="#ssh-hostkey-verification">figure 10</a>. The idea is, that either you have seen the this key beforehand or you have some other means to get this key fingerprint and verify that it indeed belongs to the server you are trying to connect to. How this works in practice or not, is a completely different discussion.</p><div> <figure style="max-width:100%;overflow:auto" class="inline-figure" id="ssh-hostkey-verification"><pre style="max-width: 100%; overflow: auto;">$ ssh example.com
The authenticity of host 'example.com (127.1.2.3)' can't be established.
RSA key fingerprint is SHA256:Cy86563vH6bGaY/jcsIsikpYOHvxZe/MVLJTcEQA3IU.
Are you sure you want to continue connecting (yes/no)?</pre><figcaption class="text-center"> Figure 10: The default SSH server key verification request on the first connection. </figcaption> </figure></div><p>As you can see, the key fingerprint is not easy to remember and also the comparison of two fingerprints can be quite hairy. When you enable visual host key support, as show in <a href="#ssh-first-connection-visualhostkey">figure 11</a>, the idea is that you can quickly glance to figure out if the key of a server is different than expected. This should not be treated as a method to see if two keys are equal, as different keys can produce the same image.</p><div> <figure style="max-width:100%;overflow:auto" class="inline-figure" id="ssh-first-connection-visualhostkey"><pre style="max-width: 100%; overflow: auto;">$ ssh -o VisualHostKey=true example.com
The authenticity of host 'example.com (127.1.2.3)' can't be established.
RSA key fingerprint is SHA256:Cy86563vH6bGaY/jcsIsikpYOHvxZe/MVLJTcEQA3IU.
+---[RSA 8192]----+
|     ..o.=+      |
|      . E.       |
|        . .      |
| .       o       |
|o o   + S o      |
|.+ o o + *       |
|o.. .o..B.o      |
|.o  o.*BB= .     |
|+ ...=o@@+o      |
+----[SHA-256]----+
Are you sure you want to continue connecting (yes/no)?</pre><figcaption class="text-center"> Figure 11: Visual host key enabled SSH server key verification request on the first connection. </figcaption> </figure></div><p>The algorithm to generate these visual host keys is visualized at <a href="#openssh-visualhostkey">figure 12</a>. It’s also described in detail in an article that analyzes the algorithmic security of this visual host key generation: <a href="http://www.dirk-loss.de/sshvis/drunken_bishop.pdf">The drunken bishop: An analysis of the OpenSSH fingerprint visualization algorithm</a>.</p><p>OpenSSH’s visual host key is formed in such way that the formation starts from the center of the image. Then 2 bits of the host key fingerprint are selected and the location is moved in a diagonal direction. The visual element on the plane where this movement happens is changed based on how many times a certain location is visited. This can be better seen from the animation where each visual host key generation step is visualized as its own frame and where the bits related to the movement are highlighted.</p><div class="text-center"> <figure class="inline-figure" id="openssh-visualhostkey"> <a href="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-2048.gif"> <picture><!--[if IE 9]><video style="display:none"><![endif]--><source type="image/apng" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-578.apng 578w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-964.apng 964w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-1412.apng 1412w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-2048.apng 2048w" sizes="578px, 964px, 1412px, 2048px"/> <source type="image/webp" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-578.webp 578w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-964.webp 964w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-1412.webp 1412w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-2048.webp 2048w" sizes="578px, 964px, 1412px, 2048px"/> <source type="image/gif" srcset="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-578.gif 578w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-964.gif 964w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-1412.gif 1412w,     https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-2048.gif 2048w" sizes="578px, 964px, 1412px, 2048px"/> <!--[if IE 9]></video><![endif]--><img src="https://barro.github.io/2018/02/avatars-identicons-and-hash-visualization/openssh-visualkey-578.gif OpenSSH visual host key generation animated.""  alt="OpenSSH visual host key generation animated." width="578" height="287" class="figure-image" title="OpenSSH visual host key generation animated"/></picture> </a><figcaption> Figure 12: OpenSSH visual host key generation animated. </figcaption> </figure></div><p>The exact details how the key is generated can be seen from <a href="https://github.com/openssh/openssh-portable/blob/77199d6ec8986d470487e66f8ea8f4cf43d2e20c/sshkey.c#L1044">OpenSSH’s source code</a>. This source code also refers to a paper called <span title="Perring, Adrian. Song, Dawn. Hash Visualization: a New Technique to improve Real-World Security."> <a href="http://www.netsec.ethz.ch/publications/papers/validation.pdf">Hash Visualization: a New Technique to improve Real-World Security</a></span>. But the fact that OpenSSH is usually limited to terminals with text interface makes it quite hard to use the more advanced <em>Random Art</em> methods described in the paper. But the idea for host key verification by using images has at least taken one form in the OpenSSH world.</p><h2 id="conclusions">Conclusions</h2><p>I presented here some methods that I have encountered over the years on various sites and programs. I can not possibly cover all of them, as there likely are as many algorithms to create avatars as there are people inventing them. The biggest question with any of these algorithms is that how many bits they should try to visualize and what types of graphical elements they can use in the visualization without just creating indistinguishable clutter.</p></li><li> <span class="post-meta">Sunday, Jan 7, 2018 • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Jussi Judin</span></span></span><h2> <a class="post-link" href="/2018/01/taking-a-look-at-python-afl/">Taking a look at python-afl</a></h2><p>I have been using <a href="http://lcamtuf.coredump.cx/afl/">american fuzzy lop</a> to <a href="https://en.wikipedia.org/wiki/Fuzzing">fuzz</a> various C and C++ programs and libraries. It is a wonderfully fast fuzzer that is generally easy to get started with and it usually finds new bugs in programs that have not been fuzzed previously. Support for american fuzzy lop instrumentation has also been added for other languages and I decided to try out how it works with <a href="https://www.python.org/">Python</a>. More specifically with the reference CPython implementation of it.</p><h2 id="fuzzing-python-programs-with-american-fuzzy-lop">Fuzzing Python programs with american fuzzy lop</h2><p>American fuzzy lop generally works by running a program that is compiled with american fuzzy lop instrumentation built in. It executes the program with <em>afl-fuzz</em> command that modifies the input data that is fed to the program, monitors how the program behaves, and registers everything that causes abnormal program behavior. This works well for natively compiled programs, but causes various issues with interpreted programs.</p><p>Python is by default an interpreted language, so to execute Python programs, you need to start a Python interpreter before executing your code. This means that if you would instrument the Python interpreter with american fuzzy lop instrumentation and run the interpreter with <em>afl-fuzz</em>, it would mostly fuzz the inner workings of the interpreter, not the actual Python program.</p><p>Fortunately there is <a href="https://github.com/jwilk/python-afl">python-afl</a> module that enables american fuzzy lop instrumentation for just the Python code instead of instrumenting the Python interpreter. In native programs american fuzzy lop compiler wrapper (<em>afl-gcc</em>, <em>afl-clang</em>, <em>afl-clang-fast</em>) adds the necessary instrumentation and the connection to <em>afl-fuzz</em>. Python-afl is, however, designed in such way that it doesn’t try to wrap the whole program, but requires you to create a wrapper module that initializes fuzzing.</p><p>The most simple way to wrap a Python program with python-afl is to initialize python-afl and then run the program (assuming that <code class="highlighter-rouge">main()</code> function exists):</p><div id="instrumentation-pre-init" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">fuzzable_module</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
</code></pre></div></div><p>This script, saved to <code class="highlighter-rouge">fuzz-wrapper.py</code>, can be then run with <em>py-afl-fuzz</em> command that wraps <em>afl-fuzz</em> for Python programs:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>py-afl-fuzz <span class="nt">-m</span> 400 <span class="nt">-i</span> initial-inputs/ <span class="nt">-o</span> fuzzing-results/ <span class="nt">--</span> <span class="se">\</span>
    python fuzz-wrapper.py @@
</code></pre></div></div><p>More details about these command line switches can be found from <a href="http://lcamtuf.coredump.cx/afl/README.txt">AFL readme file</a>. This then brings out the famous <a href="http://lcamtuf.coredump.cx/afl/status_screen.txt">american fuzzy lop status screen</a>, but now for Python programs:</p><div class="text-center"> <figure class="inline-figure" id="figure-afl-status"> <a href="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen.html"> <picture><source type="image/webp" srcset="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-736.webp 736w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-920.webp 920w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1104.webp 1104w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1472.webp 1472w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2208.webp 2208w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2900.webp 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/> <source type="image/png" srcset="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-736.png 736w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-920.png 920w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1104.png 1104w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-1472.png 1472w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2208.png 2208w,     https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-2900.png 2900w" sizes="736px, 920px, 1104px, 1472px, 2208px, 2900px"/><img src="https://barro.github.io/2018/01/taking-a-look-at-python-afl/afl-status-screen-736.png" alt="afl-fuzz status screen with python-afl. Yes, I use white background." title="afl-fuzz status screen with python-afl. Yes, I use white background." width="736" height="441" class="figure-image"/></picture> </a><figcaption><p>Figure 1: <em>afl-fuzz</em> status screen with python-afl. Yes, I use white background.</p> </figcaption> </figure></div><p>Next sections will explain in more details how to make fuzzing these programs more efficient and what pitfalls there could be in Python programs from fuzzing efficiency point of view.</p><h3 id="afl-fuzz-modes-and-their-python-afl-equivalents">Afl-fuzz modes and their python-afl equivalents</h3><p>Generally <em>afl-fuzz</em> provides 4 fuzzing modes that differ in how the program execution between different fuzzing inputs behaves:</p><ul><li><span id="afl-dumb-mode">Dumb mode that just executes the program by doing <a href="http://man7.org/linux/man-pages/man2/fork.2.html"><code class="highlighter-rouge">fork()</code></a> and <a href="http://man7.org/linux/man-pages/man3/exec.3.html"><code class="highlighter-rouge">execv()</code></a>. This is the slowest mode that does not rely on any fancy tricks to speed up program execution and also does not provide any insights how the program behaves with different inputs. </span></li><li>Basic <a href="http://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html">fork server mode</a> where the fuzzed binary does all the initialization steps that happen before calling the <a href="http://en.cppreference.com/w/cpp/language/main_function"><code class="highlighter-rouge">main()</code> function</a> and then program is repeatedly forked from that point on. This also includes instrumentation that is compiled in to the program so there already is some insight on what is happening inside the program when a specific input is processed. There exists QEMU mode for <em>afl-fuzz</em> that technically enables fork server mode for uninstrumented binaries, but with some performance penalty.</li><li><a href="https://github.com/mirrorer/afl/tree/master/llvm_mode">Deferred instrumentation</a> that works in similar fashion as the basic fork server mode. Instead forking just before calling <code class="highlighter-rouge">main()</code> function, this enables to move the fork point further down the line and enables heavy program initialization steps to be avoided if they can be executed independently of the input.</li><li><a href="https://lcamtuf.blogspot.fi/2015/06/new-in-afl-persistent-mode.html">Persistent mode</a> where the fuzzable part of the program is repeatedly executed without resetting the program memory every time the program is called. This only works in practice if the program does not have a modifiable global state that can not be reset to the previous state.</li></ul><p><em>Afl-fuzz</em> generates new inputs and analyzes the program execution results roughly at the same speed regardless of the mode. So these modes are in the order of efficiency in a sense that how much overhead there is for fuzzing one input. They are also in the order of complexity on how easy they are to integrate into an existing program that has not been made to be fuzzed. Especially as the fastest modes require <a href="http://clang.llvm.org/">clang</a> to be available as a compiler and the fuzzable program needs to be able to be compiled and linked with it.</p><p>Python-afl, fortunately, provides equivalent modes without having to use special tools. These are also very fast to try out, as you don’t need to compile Python programs from scratch.</p><p>The dumb mode would be just equivalent of running Python interpreter directly with <em>afl-fuzz</em> without any instrumentation, so we will skip over it. The more interesting part is to use the deferred instrumentation. The code in the introductory section called <code class="highlighter-rouge">afl.init()</code> before the fuzzable module was imported. This is the most safe approach, as the fuzz target might do something with the input at import time. But more realistically, Python programs generally only call <code class="highlighter-rouge">import</code> statements, possibly conditionally, during the start-up and don’t handle any user provided data yet. So in this case, we can do imports first and move the <code class="highlighter-rouge">afl.init()</code> function just before where the actual work happens:</p><div id="instrumentation-deferred" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
</code></pre></div></div><p>We can gain some speed-ups with this by calling <code class="highlighter-rouge">os._exit()</code> function instead of letting Python to exit in the usual fashion where all the destructors and other functions that are called at exit:</p><div id="instrumentation-os-exit" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>Previous examples assume that the input file generated by the fuzzer comes as the first parameter on the command line. This is quite a good assumption, as many data processing modules for Python include a command line interface where they read and process files given on the command line. But if we can directly call the data processing function, we can instead use the standard input to feed the data:</p><div id="instrumentation-os-exit-stdin" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span><span class="p">,</span> <span class="n">sys</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>With Python 3 comes additional complexity. Python 3 processes the standard input using the encoding specified in the environment. Often in Unix environments it is UTF-8. As <em>afl-fuzz</em> mostly does bit manipulation, input is going to end up with broken UTF-8 data and results in exception when reading from the standard input file object. To work around this, you can use <code class="highlighter-rouge">sys.stdin.buffer</code> instead of <code class="highlighter-rouge">sys.stdin</code> in Python 3 based programs. Or create a shim that always results in raw bytes:</p><div id="instrumentation-stdin-python23" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span><span class="p">,</span> <span class="n">sys</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Python 3:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="nb">buffer</span>
<span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
    <span class="c"># There is no buffer attribute in Python 2:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span>

<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>The fastest persistent mode requires that the program should not have a global state where the previous program execution affects the next one. There unfortunately is a surprising amount of global state in Python programs. It is not that uncommon to initialize some specific variables only during the program execution and then re-use the results later. This usually is harmless, but negatively affects the program stability that <em>afl-fuzz</em> is going to show in its status screen.</p><p>Persistent mode code for a fuzzable program could look like following including the learnings from the deferred instrumentation and its speedups:</p><div id="instrumentation-persistent" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Python 3:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="nb">buffer</span>
<span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
    <span class="c"># There is no buffer attribute in Python 2:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span>

<span class="k">while</span> <span class="n">afl</span><span class="o">.</span><span class="n">loop</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><h4 id="persistent-mode-stability">Persistent mode stability</h4><blockquote><p>This section has been added 6 months after writing the original article when Jakub Wilk pointed out potential stability issues with the original persistent mode code example on OS X and FreeBSD.</p></blockquote><p>Some systems where Python runs implement file manipulation by using buffered functions. The most prominent operating system where <em>afl-fuzz</em> runs that uses buffered I/O in Python is OS X/macOS and using the <a href="#instrumentation-persistent">persistent mode example in the previous section</a> does not work in Python 2 on these systems. It shows up as a low stability percentage in <em>afl-fuzz</em> user interface that means that the same input from <em>afl-fuzz</em> perspective leads program taking different paths between subsequent executions, as the input read by the program is not the same as what <em>afl-fuzz</em> has provided.</p><p>Buffered reads from a file work by calling low level file reading system calls with a moderately sized input buffer. This input buffer then makes sure that if we do a lot of small file system reads, like reading frame based data formats frame by frame, they will not result in as many system calls as they would result without buffering. This generally increases program performance, as programmers can rely on file system functions to work relatively fast even with non-optimal access patterns.</p><p>You need to set the stream position to the beginning when using persistent mode with <em>afl-fuzz</em> on systems that use buffered I/O and you are reading from the standard input. All these examples read data from the standard input, as it is generally more efficient than opening a new file for each fuzzing iteration. Rewinding the stream position to the beginning by using <a href="https://docs.python.org/2/tutorial/inputoutput.html#methods-of-file-objects">file.seek(0) method</a>.</p><p>Unfortunately not all streams support seeking and with <em>afl-fuzz</em> the situation is more tricky. If you execute the program normally and read from <code class="highlighter-rouge">sys.stdin</code>, by default the standard input does not support seeking. But when you run it through <em>afl-fuzz</em>, the standard input is in reality a file descriptor that is backed up by a file on a file system. And this file supports seeking. So you need some extra code to detect if the standard input supports seeking or not:</p><div id="instrumentation-persistent-rewind" class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">fuzzable_module</span><span class="p">,</span> <span class="n">os</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Python 3:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="nb">buffer</span>
<span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
    <span class="c"># There is no buffer attribute in Python 2:</span>
    <span class="n">stdin_compat</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c"># Figure out if the standard input supports seeking or not:</span>
    <span class="n">stdin_compat</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">rewind</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span> <span class="n">stream</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c"># In Python 2 and 3 seek failure exception differs:</span>
<span class="k">except</span> <span class="p">(</span><span class="nb">IOError</span><span class="p">,</span> <span class="nb">OSError</span><span class="p">):</span>
    <span class="c"># Do nothing if we can not seek the stream:</span>
    <span class="k">def</span> <span class="nf">rewind</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span> <span class="k">pass</span>

<span class="k">while</span> <span class="n">afl</span><span class="o">.</span><span class="n">loop</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">fuzzable_module</span><span class="o">.</span><span class="n">process_data</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
    <span class="n">rewind</span><span class="p">(</span><span class="n">stdin_compat</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>The effect of adding standard input rewinding more than doubles the fuzzing overhead for the persistent mode on the Debian GNU/Linux system that I have used to do these benchmarks. On OS X the effect is less than 10 % overhead increase for Python 3 and is required for Python 2 to even work with <em>afl-fuzz</em> on OS X.</p><h3 id="benchmarking-different-afl-fuzz-modes">Benchmarking different afl-fuzz modes</h3><p>I wanted to measure how these different <em>afl-fuzz</em> modes behave with Python. So I created a small fuzz target whose main algorithm does some conditional computation based on the input data and prints out the result:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fuzz_one</span><span class="p">(</span><span class="n">stdin</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">stdin</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="c"># This only includes lowercase ASCII letters:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="mi">5</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="mi">3</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="mi">2</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
</code></pre></div></div><p>This is just to exercise the fuzzer a little bit more than a trivial function that does nothing would do. I also created an equivalent fuzz target in C++ to give numbers to compare what kind of an overhead different fuzzing modes incur for both Python and native applications. The approximate results are summarized in table <a href="#table-benchmarks">1</a>. The actual scripts used to generate this data are available from following links: <a href="measure-times.sh">measure-times.sh</a>, <a href="target-simple.template.py">target-simple.template.py</a>, and <a href="target-simple.cpp">target-simple.cpp</a>.</p><div class="text-center"> <figure class="inline-figure" id="table-benchmarks"><table style="margin:0 auto"><thead><tr><th style="text-align:left"> </th><th style="text-align:right">Python 2</th><th style="text-align:right">Python 3</th><th style="text-align:right">Native</th></tr></thead><tbody><tr><td style="text-align:left"><a href="#afl-dumb-mode">dumb mode</a></td><td style="text-align:right">110/s</td><td style="text-align:right">47/s</td><td style="text-align:right">1200/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-pre-init">pre-init</a></td><td style="text-align:right">130/s</td><td style="text-align:right">46/s</td><td style="text-align:right">5800/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-deferred">deferred</a></td><td style="text-align:right">560/s</td><td style="text-align:right">260/s</td><td style="text-align:right">6800/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-os-exit-stdin">quick exit</a></td><td style="text-align:right">2700/s</td><td style="text-align:right">2100/s</td><td style="text-align:right">8700/s</td></tr><tr><td style="text-align:left"><a href="#instrumentation-persistent-rewind">rewinding persistent mode</a></td><td style="text-align:right">5800/s</td><td style="text-align:right">5900/s</td><td style="text-align:right">-</td></tr><tr><td style="text-align:left"><a href="#instrumentation-persistent">persistent mode</a></td><td style="text-align:right">17000/s</td><td style="text-align:right">15000/s</td><td style="text-align:right">44000/s</td></tr></tbody></table><figcaption class="text-center">Table 1: afl-fuzz benchmarks for various fuzzing modes for Python 2, Python 3, and for C++ versions of the example fuzz target.</figcaption> </figure></div><p>What these results show, it is possible to make fuzzable program in Python in such way that the fuzzing start-up overhead is only three to four times larger than for a native one with <em>afl-fuzz</em>. This is an excellent result considering that generally algorithms implemented in Python can be considered 10-100 times slower than ones implemented in C family languages. But if you want to use Python for performance critical tasks, you are anyways using <a href="http://cython.org/">Cython</a> or <a href="https://docs.python.org/2/extending/extending.html">write performance critical parts in C</a>.</p><p>There is a clear performance difference between Python 2.7.14 and Python 3.6.4 especially when all start-up and exit optimization tricks are not in use. This difference is also visible in Python start-up benchmarks at <a href="https://speed.python.org/">speed.python.org</a>. This difference gets smaller when the persistent mode is used as Python executable is not shut down immediately after processing one input. What can also help Python 3 in the persistent fuzzing mode is the fact that the tracing function that python-afl sets with <a href="https://docs.python.org/2/library/sys.html#sys.settrace">sys.settrace()</a> is called only half as often with Python 3 is it is called with Python 2 for this fuzz target.</p><h2 id="more-speed-for-repeated-python-executions">More speed for repeated Python executions</h2><p>Python enables imports and other type of code loading at any phase of the program execution. This makes it quite possible that program has not fully loaded before it is executed for the first time. This is usually used as a configuration mechanism to configure the program based on the runtime environment and other type of configuration. It also provides the possibility to write plugins, similarly to what <a href="https://en.wikipedia.org/wiki/Dynamic_loading">dynamically loaded libraries</a> provide.</p><p>You can see from table <a href="#table-benchmarks">1</a> how the fuzzing overhead decreases a lot when the fuzzing start point moved after <code class="highlighter-rouge">import</code> statements for this simple example program. So when I was fuzzing an old version of <a href="https://pypi.python.org/pypi/flake8">flake8</a>, I tried to see if it had any hidden configuration statements that would execute and cache their results for repeated calls. And it did!</p><p>Initially I used following type of fuzzing wrapper for flake8:</p><pre><code class="language-python2">import afl, sys, flake8.run
afl.init()
flake8.run.check_code(sys.stdin.read())
</code></pre><p>It is basically a simple wrapper that imports all what it needs and then fuzzes what is fed from the standard input to the program. But the performance of this was horrible, around 15 executions/second. So I tried to see what happens when I change the code a little bit by calling the <code class="highlighter-rouge">flake8.run.check_code()</code> function with an empty string before setting the fuzzing starting point:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">afl</span><span class="p">,</span> <span class="n">sys</span><span class="p">,</span> <span class="n">flake8</span><span class="o">.</span><span class="n">run</span>
<span class="c"># Make sure that the hidden runtime configuration is executed:</span>
<span class="n">flake8</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">check_code</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
<span class="n">afl</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">flake8</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">check_code</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</code></pre></div></div><p>This doubled the execution speed to around 30 executions/second. It is still quite slow for the small inputs that <em>afl-fuzz</em> initially creates, but an improvement nonetheless. I looked at what flake8 does when it is executed and a following line popped up:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pkg_resources</span> <span class="kn">import</span> <span class="n">iter_entry_points</span>
</code></pre></div></div><p>There basically is a hidden <code class="highlighter-rouge">import</code> statement in the execution path whose result is cached after the first time it is encountered. Also this <code class="highlighter-rouge">pkg_resources.iter_entry_points()</code> function is used to <a href="http://setuptools.readthedocs.io/en/latest/pkg_resources.html#entry-points">configure the program at runtime</a> and that also adds some extra overhead to the process.</p><p>Flake8 also by default tries to execute checks in parallel with <a href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing module</a>. This might be a good idea when you have multiple files to verify at once, but during fuzzing it just adds unneeded overhead. Also the fact that it starts a new process makes the fuzzer lose all information about what is happening in the subprocess. Fortunately in flake8 it was possible to override the detected multiprocessing support by just setting one variable into <code class="language-python highlighter-rouge"><span class="bp">False</span></code> and then flake8 will act as there is no multiprocessing support. This increased the average fuzzing speed of flake8 by threefold.</p><p>The final speedup with flake8 came when looking at how flake8 is constructed. It is basically a wrapper around <a href="https://pypi.python.org/pypi/mccabe/">mccabe</a>, <a href="https://pypi.python.org/pypi/pycodestyle/">pycodestyle</a>, and <a href="https://pypi.python.org/pypi/pyflakes/">pyflakes</a> packages. So rather than fuzz flake8, it is much more productive to create a fuzz target for each one of those packages individually. I did this for pycodestyle and ended up finally executing it with around 420 executions/second for trivial data and around 200 executions/second for more realistic. So basic recommendations on how to fuzz native programs also apply for Python.</p><h2 id="monkey-patching-around-fuzzing-barriers">Monkey patching around fuzzing barriers</h2><p>As american fuzzy lop does not know almost anything about the input, it can encounter various impediments (see section 13 from <a href="http://lcamtuf.coredump.cx/afl/README.txt">afl’s README.txt</a>) when the file format includes any values that depend on the previously encountered data. This is especially problematic with checksums and is also an issue with other mutation based fuzzers. To work around this the C world, you can generally use <a href="https://llvm.org/docs/LibFuzzer.html#fuzzer-friendly-build-mode">C preprocessor to turn off checksum verification</a> when such thing is encountered. This also applies for all other types of barriers that might skew fuzzing results, like random number usage.</p><p>Unfortunately Python does not have preprocessor support by default, so this type of conditional compiling is out of the question. Fortunately Python provides the possibility to do <a href="https://en.wikipedia.org/wiki/Monkey_patch">monkey patching</a> where you can replace functions or methods at runtime. So to make a library more fuzzer friendly, you can monkey patch all functions related to data verification to always return <code class="highlighter-rouge">True</code>, or return some constant value when checksums are considered.</p><p>I used this approach to fuzz <a href="https://pypi.python.org/pypi/python-evtx/0.6.1">python-evxt 0.6.1</a> library. Python-evxt is a library to parse Windows event log files and is one of the first hits when you search <a href="https://pypi.python.org/">Python Package Index</a> with “pure python parser” keyword. The file format includes <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check#CRC-32_algorithm">CRC32</a> checksum that will prevent the fuzzer from being able to meaningfully modify the input file, as almost all modifications will create an incorrect checksum in the file.</p><p>To monkey patch around this issue, I searched the source code for all functions that potentially have anything to do with checksum generation and made them always to return a constant value:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">Evtx.Evtx</span>

<span class="n">checksum_patches</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"calculate_header_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"header_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"calculate_data_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">ChunkHeader</span><span class="p">,</span> <span class="s">"data_checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">FileHeader</span><span class="p">,</span> <span class="s">"checksum"</span><span class="p">),</span>
    <span class="p">(</span><span class="n">Evtx</span><span class="o">.</span><span class="n">Evtx</span><span class="o">.</span><span class="n">FileHeader</span><span class="p">,</span> <span class="s">"calculate_checksum"</span><span class="p">),</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">class_obj</span><span class="p">,</span> <span class="n">method_name</span> <span class="ow">in</span> <span class="n">checksum_patches</span><span class="p">:</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">class_obj</span><span class="p">,</span> <span class="n">method_name</span><span class="p">,</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p>The <code class="language-python highlighter-rouge"><span class="n">checksum_patches</span></code> variable holds all the functions that you need to overwrite to ignore checksums. You can use <code class="highlighter-rouge">setattr()</code> to overwrite these methods on class level with an anonymous function <code class="language-python highlighter-rouge"><span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">:</span> <span class="mi">0</span></code> that always returns <code class="highlighter-rouge">0</code> and takes any arguments. Taking any number of arguments in any fashion is enabled with <code class="highlighter-rouge">*args</code> and <code class="highlighter-rouge">**kw</code> and this syntax is explained in <a href="https://docs.python.org/2/tutorial/controlflow.html#keyword-arguments">keyword arguments</a> section on Python’s control flow tools manual.</p><h2 id="takeaways">Takeaways</h2><p>I was impressed on how low fuzzing overhead Python programs can have when compared to C family languages. When looking at how python-afl is implemented, it becomes quite clear that the deferred mode of <em>afl-fuzz</em> has a great part in this where the whole Python environment and program initialization is skipped between different fuzzing runs.</p><p>Making a Python module fuzzable was also more easy than in C family languages. Although american fuzzy lop is already the easiest fuzzing engine to get started with, the fact that it uses clang to do the more advanced tricks often gives headaches when trying to get software to compile. The fact that I did not have to use any modified Python interpreter to get started but only had to <code class="highlighter-rouge">import afl</code> module made me to realize how many steps I skipped that I normally have to do when using american fuzzy lop on new systems.</p><p>Thanks to Python’s dynamic execution and monkey patching capabilities I could also try out fuzz target creation with external libraries without having to actually modify the original code. Especially selecting some specific functions to fuzz and overriding checksum generation would generally require nasty software patches with C family languages. Especially if there is <code class="highlighter-rouge">main()</code> function to override.</p><p>It was also nice to realize that the <code class="language-python highlighter-rouge"><span class="n">os</span><span class="o">.</span><span class="n">_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> equivalent in standard C library function call <code class="language-c highlighter-rouge"><span class="n">_Exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> could help make light native fuzz targets even faster. The process cleanup in this relatively trivial C++ program adds almost 30% overhead for repeated program execution. Although it will likely break any <a href="https://github.com/google/sanitizers">sanitizer</a> that does any verification work during the exit, like searching for dynamically allocated memory that was not freed.</p></li><li> <span class="post-meta">Sunday, Feb 19, 2017 • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Jussi Judin</span></span></span><h2> <a class="post-link" href="/2017/02/nanorepositories/">Nanorepositories</a></h2><p>I recently encountered a microservice antipattern called <a href="http://arnon.me/wp-content/uploads/2010/10/Nanoservices.pdf">nanoservice</a> that is described in following manner:</p><blockquote><p>Nanoservice is an Anti-pattern where a service is too fine grained. Nanoservice is a service whose overhead (communications, maintenance etc.) out-weights its utility.</p></blockquote><p>I have encountered a lot of similar situations with source code repositories where different parts of a program or a system that was shipped as a single entity were divided into smaller repositories. The code in these repositories was not used by anything else than the product (the unit of release) that the code was part of.</p><p>In the most extreme case there were thousands of smaller repositories. Many of those repositories were just holding less than 10 files in a deep directory hierarchy implementing some tiny functionality of the whole. Plus some boilerplate functionality for building and repository management that could just have been a couple of extra lines in a build system for a larger entity.</p><p>In more common cases, one product consists of dozens of smaller repositories where one or two repositories get over 90% of the whole weekly commit traffic and other repositories just get one commit here and there. Or that there are multiple interlinked repositories (see an example in <a href="http://baatz.io/posts/how-many-git-repos/">How many Git repos</a> article) that depend on each other and very often all of them need to go through the same interface changes.</p><p>Sometimes there also is a situation that all the work is done in smaller repositories and then there is one superproject[<a href="https://en.wikibooks.org/wiki/Git/Submodules_and_Superprojects">1</a>, <a href="http://svnbook.red-bean.com/en/1.7/svn.advanced.externals.html">2</a>, <a href="https://www.mercurial-scm.org/wiki/Subrepository">3</a>] that is automatically updated when a commit happens in any of its child projects. So basically you have one big repository that just consists of pointers to smaller repositories and has one unneeded layer of indirection. Also instead of making one commit that would reveal integration problems immediately, you now need to have multiple commits to reveal these issues. With some extra unneeded delay.</p><p>I would suggest calling these types of repositories nanorepositories. A nanorepository is a repository that holds a subsystem that is too limited to stand on its own and needs a bigger system to be part of. This bigger system usually is also the only system that is using this nanorepository. The nanorepository is also owned by the same organization as the larger entity it’s part of. Therefore it doesn’t give any advantages, for example, in access control. Nanorepositories can hold just couple of files, but they can also be relatively large applications that are, however, tightly coupled with the system they are part of.</p><h2 id="downsides-of-premature-repository-division">Downsides of premature repository division</h2><p>Nanorepositories are a case of premature optimization for code sharing where there is no real need for it. There are articles (<a href="http://danluu.com/monorepo/">Advantages of monolithic version control</a>, <a href="http://gregoryszorc.com/blog/2014/09/09/on-monolithic-repositories/">On Monolithic Repositories</a>) and presentations (<a href="https://www.youtube.com/watch?v=W71BTkUbdqE">Why Google Stores Billions of Lines of Code in a Single Repository</a>, <a href="https://www.youtube.com/watch?v=X0VH78ye4yY">F8 2015 - Big Code: Developer Infrastructure at Facebook’s Scale</a>) talking about the advantages of monolithic repositories, but those advantages can be hard to grasp without knowing the disadvantages of the other end.</p><p>I’ll list some issues that I have encountered when working with independent repositories. These all lead to a situation where developers need to spend extra time in repository management that could be avoided by grouping all software components that form the final product into one repository.</p><h3 id="expensive-interface-changes">Expensive interface changes</h3><p>Interface changes between components become expensive. You also need cumbersome interface deprecation policies and a way to support the old and new interface versions between repositories until the change has propagated everywhere. It can take months or years to ensure that all interface users have done the intended interface change. And if you don’t have a good search at your disposal, you still can’t be sure about it before you really remove the old interface.</p><p>With separate repositories it’s often the case that you can’t easily search where the interface you are deprecating is used at. This means that you don’t beforehand know what is actually depending on the interface. There naturally are search engines that span over multiple repositories, but they very rarely beat a simple <code class="highlighter-rouge">grep -r</code> (or <code class="highlighter-rouge">git grep</code>) command whose output you can further filter with simple command line tools. Especially if there are hundreds of small repositories that you need to include in your search.</p><h3 id="ignore-file-duplication">Ignore file duplication</h3><p>Often you need to add ignore files (<a href="https://git-scm.com/docs/gitignore"><code class="highlighter-rouge">.gitignore</code></a>, <a href="https://www.mercurial-scm.org/wiki/.hgignore"><code class="highlighter-rouge">.hgignore</code></a>, etc…) to prevent junk going in to the repository by accident. Situations that can generate junk next to your code can be for example:</p><ul><li>In-source build (versus <a href="http://voices.canonical.com/jussi.pakkanen/2013/04/16/why-you-should-consider-using-separate-build-directories/">separate build directories</a>) generated files (<code class="highlighter-rouge">*.a</code>, <code class="highlighter-rouge">*.o</code>, <code class="highlighter-rouge">*.exe</code>, <code class="highlighter-rouge">*.class</code>, <code class="highlighter-rouge">*.jar</code>…).</li><li>Using any editor that creates backup and other files next to the file you are editing (<code class="highlighter-rouge">*~</code>, <code class="highlighter-rouge">*.swp</code>, <code class="highlighter-rouge">*.bak</code>…).</li><li>Using interpreted languages, like Python, whose default implementation byte compile the scripts for faster start-up (<code class="highlighter-rouge">*.pyc</code>, <code class="highlighter-rouge">*.pyo</code>…).</li><li>Using integrated development environments that require their own project directories.</li></ul><p>All these generic ignore rules need to be included in every project in addition to project specific ignores. Other possibility is forcing these ignore rules on developers themselves instead of taking care of them centrally. In case of nanorepositories there likely is just one or two languages used per repository, so the amount of ignore rules likely depends on the development environment that the developers work with. But it’s still needless duplication when you could get by without.</p><h3 id="re-inventing-inefficient-build-system-rules">Re-inventing inefficient build system rules</h3><p>Small repositories lead into having to reinvent build system rules for every repository from scratch if you want to test and build your component in isolation. Or doing a lot of code duplication or including references to a repository including common build rules. This also applies for test runners, as different levels of testing for different languages usually have their own test runners. Sometimes multiple test runners per language, that all have some non-default options that provide various advantages in test result reporting.</p><p>Modern build systems like, <a href="https://ninja-build.org/">ninja</a> and <a href="http://bazel.io/">Bazel</a>, usually work on knowing the whole build graph of the system that they are trying to build. This makes it more easy to discover dependencies that only rebuild parts that are necessary to rebuild. Building every repository independently from each other leads into recursive build systems that treat their inputs as black boxes (<a href="https://www.yoctoproject.org/tools-resources/projects/bitbake">Bitbake</a>, <a href="https://www.npmjs.com/">npm</a>, <a href="https://maven.apache.org/">Maven</a>, <a href="https://www.gnu.org/software/make/">Make</a>…). Changes in these black boxes are either communicated with version number changes or always rebuilding the component in question. This leads into a wasteful process and resource usage when compared to <a href="https://trunkbaseddevelopment.com/">trunk based development</a> of monolithic repositories.</p><h3 id="overly-complicated-continuous-integration-machinery">Overly complicated continuous integration machinery</h3><p>One of the defining principles of modern software development is having a working continuous integration system in place. This ensures that independent changes also work when they leave developer’s machine and also work when they are integrated with the rest of the product that the change is part of. And this is done multiple times every day. This, combined with trunk based development, keeps integration issues short (minutes to days) and avoids <a href="https://wiki.debian.org/DebianReleases#Release_statistics">many-month release freezes</a> compared to branched or forked development methods.</p><p>Nanorepositories likely end up in a repository specific checks in the continuous integration machinery that only verify that the component in the repository itself works well. And if this continuous integration machinery has an automatic per repository check job generation, it likely needs to have an entry point (like <code class="highlighter-rouge">make test</code> or <code class="highlighter-rouge">test.sh</code> script) to execute those tests. And the same applies for compilation. Not to mention the extra work when trying to compile and test against different systems and runtime instrumentation (like <a href="https://github.com/google/sanitizers/wiki/AddressSanitizer">AddressSanitizer</a>).</p><p>When the component finally gets integrated with everything else and the system breaks, figuring out the exact commit where the breakage happens (besides the integrating one) can be really painful. This is because it is easily possible to have dozens to thousands of commits between component releases. See a <a href="https://9gag.com/gag/a9rPY46">physical world example</a> where components work perfectly together, but fail when integrated. And its <a href="https://9gag.com/gag/appBmD8">hotfix</a>.</p><h2 id="a-case-for-small-repositories">A case for small repositories</h2><p>Nanorepositories should not be confused with small independent repositories, as not everything needs to aim to be a part of a bigger product. A very common reason for small repositories is the combination of ownership management with shareable components. Most open source projects are such that they are owned by a certain people, or an organization, and it’s just not a good case for them to be part of anything bigger. Especially if they provide independent components that really are used by multiple external entities. Same downsides, however, generally apply to a collection of open source projects as to products consisting of multiple repositories.</p><p><img src="https://barro.github.io/2017/02/nanorepositories/id-square-400x400.png" alt="Article identicon for Feedly" style="display:none" width="400" height="400" class="webfeedsFeaturedVisual"/></p></li><li> <span class="post-meta">Sunday, May 8, 2016 • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Jussi Judin</span></span></span><h2> <a class="post-link" href="/2016/05/static-code-analysis-and-compiler-warnings/">Static code analysis and compiler warnings</a></h2><p>Compiler generated warnings are one form of <a href="https://en.wikipedia.org/wiki/Static_program_analysis">static code analysis</a> that provides a codified form of certain types of beneficial programming practices. Nowadays modern compilers used to compile C family languages (<a href="https://en.wikipedia.org/wiki/C_(programming_language)">C</a>, <a href="https://en.wikipedia.org/wiki/C%2B%2B">C++</a>, and <a href="https://en.wikipedia.org/wiki/Objective-C">Objective-C</a>) provide hundreds of different warnings whose usefulness varies depending on project and its aims.</p><p>In this article I will examine what level of issues compiler warnings can find, what is the cost of enabling warnings and analyze compiler warning flag lists for both <a href="http://clang.llvm.org/">clang</a> and <a href="https://gcc.gnu.org/">GCC</a> compilers.</p><h1 id="levels-of-static-code-analysis">Levels of static code analysis</h1><p>Compiling C family languages usually involves preprocessor, compiler, assembler, and a linker. This also leads to situation that static code analysis can be done in various phases of program construction. These generally are:</p><ul><li>Analysis on plain source files.</li><li>Analysis on preprocesses source files.</li><li>Analysis on compilation unit level.</li><li>Link-time analysis.</li></ul><p>This multi-stage program construction results in difficulties for tools that are not called with the exact same arguments providing information about preprocessor definitions, and include and library directories. For example tools like <a href="http://www.splint.org/">splint</a>, <a href="http://cppcheck.sourceforge.net/">Cppcheck</a>, and many editor front-ends work outside the build system and can result in false warnings because they can not see inside some macro definitions that were not included in the simple static analysis setup. This becomes an issue with larger projects that do not necessarily have the most straightforward build setups and the most trivial header file inclusion policies. This does not mean that such tools are useless, but they will result in false positive warnings that can be really annoying unless they are silenced or ignored in some way.</p><p>Analysis on preprocessed source files already provides pretty accurate picture of what kind of issues there can be in the program, but it necessarily is not enough. In the compilation phase compilers constantly transform the program into new, functionally equivalent, forms during optimization phases that can even result in <a href="http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_14.html">unexpected code removal</a> that is not necessarily trivial to notice. Compilation phase also gives more opportunities for target platform specific static code analysis. For example pipeline stalls or value overflows due to incorrect assumptions on data type sizes can usually be noticed only after the target platform is known.</p><p>Final phase in program construction, that provides options for static analysis, is the linking phase. In the linking phase linker takes care that all the functions and global variables that the program calls come from somewhere and that there are no conflicting duplicate names defined. This should also enable some automatic detection capabilities for memory leaks and such that come from calling functions defined in different compilation units. I’m not sure if any freely available static analyzer does this.</p><h1 id="compiler-warning-flags">Compiler warning flags</h1><p>Compiler warning flags are one way to do static code analysis that cover all possible phases of program construction. This assumes that the compiler is involved in all phases of program construction. And they usually are, as in all phases from preprocessing to linking compiler front-end is used as a wrapper to all the tools that do the actual hard work.</p><h2 id="warning-flags-and-compilation-time">Warning flags and compilation time</h2><p>Using static code analysis in form of compiler warnings incurs some penalty, as they need to execute some extra code in addition to normal code related to compilation. To measure the penalty and to contrast it with some more advanced static analysis tools,</p><p>I did some benchmarks by compiling <a href="http://cppcheck.sourceforge.net/">Cppcheck</a> 1.73 and <a href="http://www.fftw.org/">FFTW</a> 3.3.4 with clang 3.8, GCC 6.1, and Infer 0.8.1 by using <code class="highlighter-rouge">-O3</code> optimization level. Cppcheck is a program mainly written in C++ and FFTW is mainly written in C. Infer has some experimental checks for C++ enabled with <code class="highlighter-rouge">--cxx</code> command line option, so I ran Infer twice for Cppcheck, with and without C++ checks. Clang had all warnings enabled <code class="highlighter-rouge">-Weverything</code> and GCC had all warning options that did not require any special values. This resulted in following minimum execution times of 3 runs:</p><table><thead><tr><th>Compiler</th><th>Program</th><th style="text-align:right">No warnings</th><th style="text-align:right">All warnings</th></tr></thead><tbody><tr><td>clang</td><td>Cppcheck</td><td style="text-align:right">59.3 s</td><td style="text-align:right">1 min 1.1 s (+ 3.0 %)</td></tr><tr><td>GCC</td><td>Cppcheck</td><td style="text-align:right">1 min 32.7 s</td><td style="text-align:right">1 min 38.8 s (+ 6.6 %)</td></tr><tr><td>Infer</td><td>Cppcheck</td><td style="text-align:right">-</td><td style="text-align:right">17 min 50 s (18x slower)</td></tr><tr><td>Infer <code class="highlighter-rouge">--cxx</code></td><td>Cppcheck</td><td style="text-align:right">-</td><td style="text-align:right">1 h 36 min (<strong>97x slower</strong>)</td></tr><tr><td>clang</td><td>FFTW</td><td style="text-align:right">40.5 s</td><td style="text-align:right">40.9 s (+ 1 %)</td></tr><tr><td>GCC</td><td>FFTW</td><td style="text-align:right">42.7 s</td><td style="text-align:right">58.1 s (<strong>+ 36 %</strong>)</td></tr><tr><td>Infer</td><td>FFTW</td><td style="text-align:right">-</td><td style="text-align:right">4 min 43 s (10x slower)</td></tr></tbody></table><p>We can see that for clang and GCC the extra processing time added even by all warnings flags is pretty small compared to all the other compilation and optimization steps for a C++ application (Cppcheck). But for mostly C based application (FFTW) GCC gets surprisingly heavy, although build times still remain within the same order of magnitude.</p><p>If we then compare the time that a more heavy static code analyzer takes, these compiler warnings are extremely cheap way to add static code analysis. They may not catch all the same bugs as these more advanced methods do, but they do offer a cheap way to avoid the basic mistakes.</p><h1 id="warning-flag-lists">Warning flag lists</h1><p>I have created a project that can automatically parse <a href="https://github.com/Barro/compiler-warnings">compiler warning flags from command line option definition files in clang and GCC</a>. This came partially from a necessity and partially from curiosity to examine what kind of options clang and GCC provide in easy to digest format. Although both compiler provide some kind of lists of warning flags as part of their documentation, they are pretty cumbersome to go through when the main interest is first figure what there is available and then just look at the details.</p><h2 id="warning-options-and-deprecation">Warning options and deprecation</h2><p>Different compilers have different policies about backwards compatibility and deprecation. When looking at how warning options have evolved, GCC has not removed between versions 3.4 and 6.1 a single switch, it has just switched them to do nothing (<code class="highlighter-rouge">-Wimport</code>, <code class="highlighter-rouge">-Wunreachable-code</code>, and <code class="highlighter-rouge">-Wmudflap</code> switches). Clang on the other hand has removed multiple switches between versions and for example there is no references to <code class="highlighter-rouge">-Wcxx98-cxx11-compat</code> in the current codebase even if clang 3.3 had such switch.</p><h2 id="examining-differences-visually">Examining differences visually</h2><p>Generating large purely textual differences between different files becomes quite cumbersome quite soon if you want to do anything more complicated than a simple difference of unique command line options between two subsequent versions. For example if we look at <a href="#figure-gcc-5-6-wall">figure 1</a> that shows what other warnings <code class="highlighter-rouge">-Wall</code> flag enables in GCC 6 when compared to GCC 5. We can see that there are quite many extra warnings added to <code class="highlighter-rouge">-Wall</code> switch so newer compiler versions provide extra analysis capabilities even without adding all the new options individually.</p><div class="text-center"> <figure class="inline-figure" id="figure-gcc-5-6-wall"> <a href="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-wall.png"> <picture><source type="image/webp" srcset="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-wall.webp 887w" sizes="887px"/> <source type="image/png" srcset="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-wall.png 887w" sizes="887px"/><img src="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-wall.png" alt="Meld showing differences what flags
-Wall enables between GCC 5 and 6." title="Meld showing differences what flags -Wall enables between GCC 5 and 6." width="700" height="469" class="figure-image"/> </picture> </a> <figcaption><p>Figure 1: <a href="http://meldmerge.org/">Meld</a> showing differences what flags <code class="highlighter-rouge">-Wall</code> enables between GCC 5 and 6.</p> </figcaption> </figure></div><p>From <a href="#figure-gcc-5-6-cxx-compat">figure 2</a> we can also see that GCC 6 uses <code class="highlighter-rouge">-Wc++11-compat</code> as the default warning flag indicating differences between ISO C++ 1998 and ISO C++ 2011 for constructs that have the same name instead of <code class="highlighter-rouge">-Wc++0x-compat</code>, that refers to a draft standard. So GCC has basically deprecated <code class="highlighter-rouge">-Wc++0x-compat</code> switch in favor of a switch that refers to the actual standard.</p><div class="text-center"> <figure class="inline-figure" id="figure-gcc-5-6-cxx-compat"> <a href="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-cxx-compat.png"><picture><source type="image/webp" srcset="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-cxx-compat.webp 887w" sizes="887px"/> <source type="image/png" srcset="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-cxx-compat.png 887w" sizes="887px"/><img src="https://barro.github.io/2016/05/static-code-analysis-and-compiler-warnings/meld-gcc-5-6-cxx-compat.png" alt="-Wc++0x-compat is an alias of -Wc++11-compat in GCC 6 instead the other way around." title="-Wc++0x-compat is an alias of -Wc++11-compat in GCC 6 instead the other way around." width="700" height="99" class="figure-image"/></picture> </a> <figcaption><p>Figure 2: <code class="highlighter-rouge">-Wc++0x-compat</code> is an alias of <code class="highlighter-rouge">-Wc++11-compat</code> in GCC 6 instead the other way around.</p> </figcaption> </figure></div><h1 id="suggestions-for-usable-warning-options">Suggestions for usable warning options</h1><p>I won’t be giving any specific suggestions here for warning flags, as there seem to be new options for each subsequent compiler release. A good place to start is <a href="https://www.nasa.gov/">NASA</a>’s <a href="http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf">JPL Institutional Coding Standard for the C Programming Language</a> that includes a very short list of rudimentary warning flags for GCC. It also includes a short list of coding standards of which <a href="https://vimeo.com/84991949">each one would have prevented a mission failure</a> for NASA. <a href="https://www.securecoding.cert.org/">SEI CERT coding standards</a> for secure coding also provide various automatically generated lists for <a href="https://www.securecoding.cert.org/confluence/display/cplusplus/Clang">clang warning flags</a> and <a href="https://www.securecoding.cert.org/confluence/display/cplusplus/GCC">GCC warning flags</a> based on the issues that these standards take into account.</p><p>And finally, check out the <a href="https://github.com/Barro/compiler-warnings">warning flag lists for clang and GCC</a> and make your own combinations that bring the most benefit for whatever you are working with. Not all of them are appropriate for your project and some of them may be even working against the useful development patterns that you have.</p><h2 id="cautionary-tales-about-compiler-warnings-flags">Cautionary tales about compiler warnings flags</h2><p>Even though it might sound like a good idea to rush and fix all the issues that these new compiler warning flags uncover, it might actually cause some new bugs to pop up. Specifically <a href="https://www.sqlite.org/">SQLite</a> database engine has had its own take on <a href="https://www.sqlite.org/testing.html#staticanalysis">compiler warnings and their fixing</a> and they have concluded that fixing compiler warnings actually has produced some extra bugs that would not have come into light if there would have not been tries to fix compiler warnings.</p><p>I have also had my own take on compiler warning fixes and sometimes I have screwed up and messed up with a perfectly working code while fixing a misleading warning. But generally my own experience has lead to more fixes than what there have been bugs. And the coolest thing is, that having these warnings enabled as the standard development process prevent some bugs from ever creeping up to the application in the first place.</p></li></ul><div class="previous-next-pages"> <a href="/page-2/">Older articles</a> • Page 1/2</div><p class="rss-subscribe">subscribe <a href="https://feeds.feedburner.com/jussijudin">via RSS</a></p></div></div></div><footer class="site-footer"><div class="wrapper"><h2 class="footer-heading">Jussi Judin's weblog</h2><div class="footer-col-wrapper"><div class="footer-col footer-col-1"><ul class="contact-list"><li>Jussi Judin</li><li>jju<span>din</span>+github <span>AT</span> iki DOT <span>f</span>i</li></ul></div><div class="footer-col footer-col-2"><ul class="social-media-list"><li> <a href="https://github.com/barro" title="Barro">GitHub</a></li><li> <a href="https://bitbucket.org/barro" title="barro">Bitbucket</a></li><li> <a href="https://facebook.com/b4rr0" title="B4rr0">Facebook</a></li><li> <a href="https://twitter.com/B4rr0" title="@B4rr0">Twitter</a></li><li> <a href="https://plus.google.com/+JussiJudin-jj/" title="+JussiJudin-jj">Google+</a></li></ul></div><div class="footer-col footer-col-3"><p>Programming related topics. Maybe even some original content!</p></div></div></div></footer><script>!function(e,a,t,n,c,o,s){e.GoogleAnalyticsObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},e[c].l=1*new Date,o=a.createElement(t),s=a.getElementsByTagName(t)[0],o.async=1,o.src=n,s.parentNode.insertBefore(o,s)}(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","UA-71880517-1","auto"),ga("send","pageview")</script></body></html>